# 螺旋调教 & TCSolution前段条件满足迭代

***

<!-- TOC -->

- [螺旋调教 & TCSolution前段条件满足迭代](#螺旋调教--tcsolution前段条件满足迭代)
  - [n28p01 回测](#n28p01-回测)
  - [n28p02 迭代Canset前段条件满足](#n28p02-迭代canset前段条件满足)
  - [n28p03 回测条件满足代码](#n28p03-回测条件满足代码)
  - [n28p04 回测识别越来越准问题](#n28p04-回测识别越来越准问题)
  - [n28p05 解决条件满足不完全问题](#n28p05-解决条件满足不完全问题)
  - [n28p06 回测条件满足功能 & 修复S没后段问题](#n28p06-回测条件满足功能--修复s没后段问题)
  - [n28p06B 回测大整理: 旧有拉下的测试项整理](#n28p06b-回测大整理-旧有拉下的测试项整理)
  - [n28p07 测canset再类比很少 & S准确度很低](#n28p07-测canset再类比很少--s准确度很低)
  - [n28p08 使S竞争越来越准:`整体分析 + 前段部分`](#n28p08-使s竞争越来越准整体分析--前段部分)
  - [n28p09 使S竞争越来越准:`中段部分 + 后段部分`](#n28p09-使s竞争越来越准中段部分--后段部分)
  - [n28p10 使S竞争越来越准:`测试`](#n28p10-使s竞争越来越准测试)

<!-- /TOC -->

## n28p01 回测
`CreateTime 2022.12.29`

在n27末，做了概念与时序的综合竞争,本节从其测试入手,看是否实现了概念和时序的优中择优;

| 28011 | 回测前分析 |
| --- | --- |
| 回顾 | 在2722f中,概念时序识别后,立马进行了refStrong和contentStrong增强 |
| 问题 | 在后续持续激活(有用)时,是否应该续杯(再增强strong)? |
|  | 比如: 时序跟进顺利了,然后引发了思考,解决了问题,等等; |
| 先测 | 或者先测下,如果跑着没实现优者更优,再来做这个; |

| 28012 | 回测训练 |
| --- | --- |
| 说明 | 回测下概念和时序的自然竞争,并训练下危险/安全地带; |
| 训练 | 依2722c步骤训练得FZ67; |

| 28013 | 触发器时间为0导致无效方案P值高的BUG |
| --- | --- |
| 复现 | `FZ67,危险地带,直投`,发现执行方案的末帧deltaTime=0,导致反省为P; |
| 示图 | ![](assets/663_触发器时间为0导致无效方案P值高的BUG.png) |
| 调试 | 经调试,canset本来就没Mv指向,所以=0; |
| 方案 | 应继承任务的mvDeltaTime,等pFo自然无解时,此处再触发即是准确的; |
| 结果 | 改为pFo.mvDeltaTime后,回测重训FZ68后ok,不再有此BUG `T`; |

| 28014 | 取得无效解决方案且未有效执行BUG |
| --- | --- |
| 问题 | `FZ68,危险地带,扔木棒`,测得下图问题,取得方案无效,且未有效执行; |
| 说明 | 本表重点关注取得`解决方案`的有效性,并能够有效执行后解决实际问题; |
| 示图 | ![](assets/664_解决方案起始帧为末帧无行为且未解决问题.png) |
| 如图 | 偏上0.2的危险地带,取得解决方案为`偏下0.6`,且为末帧,无行为输出; |
| 分析1 | 找个实例,是解决方案的过去帧导致其有效,如果没有过去帧,则致其无效; |
|  | 实例: 张三做饭,小红就开心,如果张三买饭,小红不一定开心; |
| 分析2 | 能不能使`有行为输出的解决方案`更有优先级? |
|  | 分析: 即更全时序条件满足,比如前段全匹配且已发生; |
| 分析3 | 现代码用indexDic判断截点,indexDic即mIsC容易不太匹配时也有关联; |
|  | 说明: 学习后期`危险地带`很明确时,是否改为contains判断匹配; |
| 方案 | 综上三条分析,即前段必须全contains满足,才做为解决方案并行为化后段; |
| 结果 | 即本问题其实是`solutionFo前段条件满足`问题,`代码实践转n28p02`; |

***

## n28p02 迭代Canset前段条件满足
`CreateTime 2023.01.04`

在上节测试中,发现`无效解决方案`的问题,后经28014的三条分析,解决方案的前段应由瞬时序列判断contains成立,然后行为化后段,本节重点对其代码实践;

| 28021 | 迭代Canset前段条件满足-实践前回顾现有相关代码 |
| --- | --- |
| 回顾 | 在27224中: `canset前段如果有遗漏,则当前canset为无效方案` |
| 例如 | [准备好枪,老虎出现,开枪吓跑],还没准备枪老虎就出现,则方案无效; |
| 分析 | 在27224中,是判断canset包含pFo已发生部分; |
| 问题1 | 27224好像并没有正面解决此问题,因为indexDic的缘故,它似乎必然满足; |
|  | > 原因: canset与pFo有indexDic所以肯定关联,但关联过度广泛(泛而不准) |
|  | > 分析: 所以现在需要改为contains判断,不能依赖indexDic; |
| 问题2 | `准备枪`肯定不在瞬时记忆中,那么我们不能通过瞬时序列判断contains; |
|  | 分析: 那么它就在工作记忆树中,比如路径如下: |
|  | 目标: 顺着pFo,找出它当时识别的matchAlgs,进而判断contains; |
|  | 因为: protoFo/regroupFo本来就是protoAlg或feedbackProtoAlg组成; |
|  | 结果: 所以protoAlg的抽象即matchAlgs `转28022-todo1`; |
| 结果 | 综上,现有代码27224压根没起到作用,本次条件满足代码改动`转28022`; |

| 28022 | 迭代Canset前段条件满足-R任务-代码实践 |
| --- | --- |
| todo1 | 顺着工作记忆找出每帧的概念识别结果matchAlgs `T`; |
| todo2 | 判断每帧的matchAlgs是否包含对应的cansetAlg `T`; |
| todo3 | TCSolution的cansets写前段条件满足代码 (一帧不包含则过虑掉) `T`; |
| todo4 | 所有已发生帧,都要判断一下条件满足 (<ptAleardayCount部分) `T`; |
| todo5 | 将前段条件满足功能写到`canset候选集过滤器`中 `T`; |
| todo6 | matchFo是抽象的,所以它缺帧时的满足也需要判断 `转28023`; |

| 28023 | 分析一下canset的前段在match中不具备的帧 |
| --- | --- |
| 比如 | matchFo是[遇老虎],cansetFo是[拿枪,遇老虎] |
| 说明 | 此时,即使canset的遇老虎条件满足,但拿枪未必满足; |
| 思路 | 所以要从protoFo中,看有没有(拿枪),而这一判断不能依赖matchFo; |
| 结果 | 本节具体方案和代码实践: `转28051 & 28052`; |

| 28024 | 迭代Canset前段条件满足-H任务 |
| --- | --- |
| 说明 | 在28022中,仅对R任务做了做了代码实践,H任务放在本表进行 |
| 示图 | ![](assets/665_H任务前段条件满足判断方法示图.png) |
| 问题1 | 怎么取H任务时的综合indexDic? |
| 回答1 | 从工作记忆树的末枝向头枝递归找R任务下的protoFo; |
|  | 每一次递归,都将执行过的indexDic累计为sumIndexDic `代码转28025-2`; |
| 问题2 | 问题1中的sumIndexDic累计方式是什么? |
|  | 设: 将已累计的讲为sumIndexDic,新一条计为itemIndexDic; |
| 回答2 | sum是具象,item是抽象,故sum中的抽象等于item的具象时,综合记为新的; |
|  | 比如: sum<抽2,具1>,item<抽3,具2>,因为sum的抽(2)=item的具(2); |
|  | > 所以最终得出的结果就是newSumIndexDic<抽3,具1> `代码转28025-3`; |
| 结果 | 如上H任务的indexDic综合计算方式代码实践转28025; |

| 28025 | 迭代Canset前段条件满足-H任务-代码实践 |
| --- | --- |
| todo1 | 将basePFoOrTargetFo在短时记忆树R下层的每层H中一直传递 `T`; |
| todo2 | 写H向工作记忆树根方向找R.protoFo的递归方法 `T`; |
| todo3 | 递归方法中,计算28024回答2中sumIndexDic的方式 `T`; |
| todo4 | 找到R.protoFo后,退出递归,算法可复用28022中R任务时的代码 `T`; |
| todo5 | 前段条件满足的代码,也复用28022中R任务时的代码 `T`; |
| todo6 | 将H任务递归算法写成最终返回cansetMatchIndexDic `T`; |
| todo7 | H任务取cansetMatchIndexDic与R任务取它复用一个算法 `T`; |
| todo8 | H任务向root方向找pFo (R任务也封装复用一个算法) `T`; |

结果: R和H任务的前段条件满足代码全写了,但28023空帧的问题还未写,后面再写;

***

## n28p03 回测条件满足代码
`CreateTime 2023.01.13`

| 28031 | 回测条件满足代码 |
| --- | --- |
| 第一轮测试 | 经`FZ6802,再跑第二步训练`测试,发现R任务跑条件满足代码大致ok; |

| 28032 | 识别不够准的问题 |
| --- | --- |
| proto | A6059(高100,Y207,皮0,X2,Y距_偏下0.4_59,距129,X距374) |
| match | A1765(高100,Y207,皮0,X2,距80,Y距_路下1.4_123,X距213) |
| 问题 | A6059偏上0.4,却识别到A1765路下1.4,可见不够准; |
| 方案 | 可以边训练边观察一下识别结果,是否变的越来越准,如果是那就加训解决; |

| 28033 | 以往训练步骤 `训练无果,但经分析制定了修改方案` |
| --- | --- |
| 步骤1 | 随机出生位置:`随机位置扔木棒,重启`x200轮 & `左棒,重启`x100轮x3次 |
| 说明 | 训练完后,观察日志,看有没有越来越明确的识别结果; |
| 问题 | 经训练,概念识别准确度提升不明显,到最后偏上0.4还是会识别有路下1.5; |
| 关键 | 识别无法越来越准会导致很多问题; |
|  | 比如: 这次在决策时判断前置条件满足时就出现因为这里而不准的情况; |
| 分析1 | 识别竞争里也有sp竞争,所以重新调整下训练步骤试试 `转28034` |
|  | > 识别竞争是相似度和强度,没有sp,所以28034无意义; |
| 分析2 | 也有可能这识别结果很正常,但要分析下,能不能辨别它的危险性很低; |
|  | > 即在安全位置时,危险可能性不是90%左右,而是接近0%; |
|  | > 而这种安全性,在识别中,也只能通过相似度来辨别 (识别时只有相似度); |
|  | > 即,可能需要辨别出哪些细节是重要的,哪些不重要,更理性的判断相似度; |
| 方案 | 根据`分析2`,目前的相似度是求和`sumNear/sumCount`,应改为求乘; |
|  | 比如: `求和: 1+1+0.7/3=0.9`,`求乘: 1*1*0.7=0.7`; |
| 结果 | 本表确定了识别时相似度改为求乘的方案,代码实践转28035; |

| 28034 | 调整训练步骤 `废弃` |
| --- | --- |
| 规划 | 识别的综合竞争中含sp竞争,所以学撞学躲都要训练(交替执行&增加步数) |
| 步骤 | 按以下步骤在随机出生位置训练300轮; |
|  | 单步: `随机位置扔木棒,重启,左棒,重启,随机飞或左棒x5,重启`; |
| 目标 | 训练完后,观察日志,看有没有越来越明确的识别结果; |
| 问题 | 经训练,概念识别准确度提升不明显,到最后偏上0.7还是会识别有路下1.6; |
| 结果 | 识别竞争依据是相似度和强度,没有sp,所以本表无用 `废弃`; |

| 28035 | 识别时相似度改为求乘-TODOLIST |
| --- | --- |
| todo1 | 概念识别计算sumNear用相乘 `T`; |
| todo2 | 时序识别计算sumNear用相乘 `T`; |
| todo3 | 在compareCansetFo()中前段匹配度也改为相乘(参考26128-1-4)`T` |
| todo4 | 检查以上三个初始相似度由0改为1 `T`; |

***

## n28p04 回测识别越来越准问题
`CreateTime 2023.01.20`

在上节中，修复了识别没能越来越准问题，本节：
1. `回测下训练时能越来越准`
2. 然后再`回测条件满足的功能`
3. 解决`28023空帧的问题`

| 28041 | 回测 (参考2722c步骤) |
| --- | --- |
| 步骤1 | 随机出生位置: `随机位置扔木棒,重启`x200轮 & `左棒,重启`x100轮 |
| 步骤2 | 随机偏中出生位置: `随机飞/扔木棒,重启` x 100轮 |
| 目标 | 观察下步骤1的训练能不能越来越准 (可考虑加训步骤1); |
| BUG1 | **步骤1训练后,发现识别结果多数仅有1条,且还是protoAlg自身;** |
| 思路1 | 看起来,有时识别不到protoAlg; |
|  | 分析: 应该是纯新的protoAlg时识别不到(经实证识别的就是纯新protoA); |
|  | 反方: 旧的即使一模一样也应被识别到,所以不用改吧? |
|  | 修复: 识别到的就是纯新protoAlg,所以将其改为不应期,不被识别到`T` |
| 思路2 | 多数只有一条,可以降低一下相似度,毕竟改成相乘后,相似度值低; |
|  | 分析: 改成综合排序后,相似度低的也排不到前面,无非是自由竞争; |
| 修复 | 根据思路2,先将相似度阈值降到0.6,经改后重测还ok `T`; |
| BUG2 | **BUG1修复后ok,但准确度仍需提高下;** |
| 说明 | 如概念识别常有`偏上0.4识别为偏下0.2` (其相似度为0.6左右); |
| 思路 | 加训步骤1,使它准确度更高: 步骤1训练3次; |
| 结果 | BUG2的思路训练,转28042; |

| 28042 | 继续回测训练 |
| --- | --- |
| 步骤1 | 随机出生位置:`随机位置扔木棒,重启`x200轮 & `左棒,重启`x100轮x3次 |
| 步骤2 | 随机偏中出生位置: `随机飞/扔木棒,重启` x 100轮 |
| BUG | 训练得到FZ69,但有些强度太强,以致相似度低也被识别到,如下图: |
| 示图 | ![](assets/666_相似度低也识别到问题.png) |
| 思路1 | 可以查下知识结构,应该是场景太单一不够丰富所致; |
|  | 否决: 经查,知识结构并不单一,有丰富多样的抽具象 `否掉`; |
| 思路2 | 图中A692强度太高,导致相似度低也识别到; |
|  | 分析: 继续查下强者愈强的竞争是否顺畅; |
|  | **1. v索引加个20%的激活率 (相似度低的没资格激活)。** |
|  | > 可加 `已实践,返回20%且至少10条 T`; |
|  | **2. alg.rank的两项，看用不用加个权重？(项外权重是个百分值)** |
|  | > 可先不加,因为这个权重值很难定,或者需要更明确时,再来加; |
|  | **3. 单项的权重也可以前面更强，后面更弱(牛顿冷却曲线？)** |
|  | > 可加,现在是线性的,加上曲线对越准确的越有优势 `已根据28原则实践 T`; |
|  | **4. 取消概念识别结果相似度阈值,使其训练中自然越来越准即可 `T`** |
| 结果 | 修改思路2后,重训FZ70,准确度提升ok,第1步首次100轮就有成效 `T`; |

| 28043 | 28042-思路2代码实践-todo |
| --- | --- |
| 1 | v加20%激活,且不小于10条 `T`; |
| 2 | AIRank里概念与时序识别的排名,套用牛顿冷却 `T`; |
| 3 | AIRank里`S综合排名`,套用牛顿冷却+各项相乘 `未做,待需求明确时再做` |
| 4 | 取消概念识别结果过滤器中的"相似度阈值过滤" `T`; |
| 5 | 测下时序识别有没有越来越准 `需求未明确,先不测`; |

结果: 本节修改后:概念识别越来越准ok了,剩下两个需求未明确的后面再做:
1. `AIRank.S综合排名`改冷却+相乘未改;
2. 时序识别的越来越准确未测;

***

## n28p05 解决条件满足不完全问题
`CreateTime 2023.02.02`

在上节中，修复并回测了识别没能越来越准问题，本节：
1. `回测条件满足的功能`
2. 解决`28023空帧的问题: 条件满足不完全问题`
3. `回测Solution取得有效解决方案的问题 (参考条件满足之前的手稿)`

| 28051 | 回测条件满足-又测得28023的空帧问题 |
| --- | --- |
| 问题 | 本表主要描述了canset前段条件满足判断不完全问题 `前因场景不同`; |
| 示图 | ![](assets/667_又测得条件满足的空帧问题.png) |
| 说明 | 如图,此处仅对canset的第3帧判断了条件满足,但前两帧却都未曾满足; |
| 分析 | 前因和后果,可能前面的每一帧都很重要,少一帧场景条件也不一样; |
| 示例 | 参考canset=[拿枪,遇老虎]示图,此时遇到老虎,但可能没拿过枪; |
|  | 可能matchFo中压根不要求枪,并且有可能protoFo中也没满足枪条件; |
| 思路 | 即:cansetFo的前段条件必须全满足 (protoFo中有mIsC指向它); |
| 方案 | canset前段部分从前向后逐帧判断,必须全被protoFo满足,实践`转28052` |

| 28052 | Canset前段条件满足不完全问题-代码实践TODOLIST |
| --- | --- |
| 1 | 根据pFoOrTargetFo.ptAleardayCount取得对应canset的中段截点 `T` |
|  | 提示: ptAleardayCount = cutIndex+1或actionIndex; |
| 2 | 在CansetFosFilter()遍历cansetFo前段,判断protoFo条件满足 `T`; |
| 3 | 单条cansetAlg判断满足: `用protoAlg有mIsC指向cansetAlg为准` `T`; |
| 4 | 在CansetFosFilter()过滤掉canset后段没元素的(行为化有可做的) `T`; |

***

## n28p06 回测条件满足功能 & 修复S没后段问题
`CreateTime 2023.02.04`

在上节中，修复条件满足不完全问题,本节:
1. `回测条件满足的功能`
2. `回测Solution取得有效解决方案的问题 (参考条件满足之前的手稿)`

| 28061 | 经测所有解决方案都没后段BUG |
| --- | --- |
| 复现 | `FZ7002,位置路偏上,直投` |
| 分析 | FZ70的训练,应该在投出后,没有紧跟着躲的经验; |
| 方案 | 可以手动训练一下,在投出木棒后,紧跟着手动躲下,经历几次躲成功经验; |

| 28062 | 规划训练步骤 |
| --- | --- |
| 步骤1 | 随机出生位置:`随机位置扔木棒,重启`x200轮 & `左棒,重启`x100轮x1次 |
| 步骤2 | `路偏上位置,直投,上飞躲开,重启`x5 |
| 训练 | 经以上两步训练,得FZ71; |
| BUG1 | 刚开始训练第一步时AITest14中断,后查下原因; |
| BUG2 | `7102,路偏上位置,直投`,日志中Solution没有解决方案 `转28063`; |

| 28063 | BUG2: 解决方案候选集全没后段-> pFo实际经历新增不相关帧 |
| --- | --- |
| 说明 | 1. 在第2步训练时,识别和形成R任务的pFo都是`F879,F892,F893` |
|  | 2. 最后测试时,也是这三个,但就是rSolution取到0条方案; |
| 示图 | ![](assets/668_FZ71测得解决方案候选集为0条的BUG.png) |
| 调试1 | 经调试,F879取得7条解决方案,但七条全没后段被过滤了`参考28052-4`; |
|  | 思路: 进一步调试第2步训练时,为何未生成有后段的候选方案? `转调试2`; |
| 调试2 | 经查代码,具象canset是由pFo.realMaskFo生成的; |
|  | 构成: 而realMaskFo是由反馈成功时的一帧帧proto拼起来的; |
|  | 线索: 因为上飞不算反馈,没法加入realMaskFo,故无法生成到canset中; |
| 思路 | 参考调试2,pFo.realMaskFo实际经历中,缺了不相关却有用的帧; |
| 方案 | 需要将不算反馈的`上飞`,也加入到生成canset中,此问题即解; |
| todo1 | 新写pFo.feedbackOtherFrame(){反馈不匹配时也记录实际发生帧}`T` |
| todo2 | feedbackTIR中只要wait且未匹配到,即调用feedbackOtherFrame`T` |
| 结果 | 经代码实践方案后,此BUG已修复,可以生成有后段的S候选集了 `T`; |
| 惊喜 | 本表realMaskFo借助工作记忆,实现了更长的时序时间跨度 `参考27114`; |

***

## n28p06B 回测大整理: 旧有拉下的测试项整理
`CreateTime 2023.02.09`

| 28064 | 回测大整理: 递归手稿中测试项 (从近到远) |
| --- | --- |
| 1 | 测条件满足功能 `T`; |
| 2 | 测Solution取得有效解决方案; |
| 3 | 测训练得到危险/安全地带; |
| 4 | 测训练`可躲避防撞` `参考28065-训练 T`; |
| 5 | 测触发canset再抽象 `T 转28071&28077`; |
| 6 | 测有没有matchValue为0的BUG |
| 7 | 测下反思识别能够顺利工作(有反思不通过的情况) |
| 8 | 测下`安全地带不躲` (反思评价: 危险小而懒得动) `参考28065-训练 T`; |
| 9 | 测下飞错方向问题 `实现各向飞躲` `参考n26p06` `参考28065-训练 T`; |
| 10 | 删除快思考和effectDic相关代码 `暂不做,随后再删 T`; |
| 11 | 测下任务失效机制 `参考n27p10`; |
| 12 | 考虑实现紧急状态 `参考26241`; |
| 13 | 考虑决策时的综合竞争Rank改成相乘 `参考n26p21` `T`; |
| 14 | 测连续飞躲:飞躲->H反馈->重组->反思->子任务->继续飞躲`参考n26p18` |
| 15 | 回测觅食训练; |

| 28065 | 重训防撞: 结果顺利 |
| --- | --- |
| 第1步 | 随机出生位置:`随机位置扔木棒,重启`x200轮 & `左棒,重启`x100轮x1次 |
| 第2步 | 手动偏上上躲5次,偏下下躲5次,上下各加训3次; |
| 训练 | 训练得到FZ72,并在它上面测单向躲成功,多向躲成功,安全地带不躲成功; |

| 28066 | 改强训工具学躲代码,使之实现手动躲效果 |
| --- | --- |
| 说明 | 在28065中,第2步是人工训练的,本表实现强训工具自动训练; |
| todo1 | 在训练页,扔出木棒,然后5次随机方向飞 `T`; |
| todo2 | 实现在反射飞kFlySEL执行时,不必等待TC空载即执行 `T`; |
| todo3 | 写queue强训项支持传递参数 (以支持指定方向飞行) `T`; |
| 结果 | 以上代码实现后,重新规划飞躲强训步骤 `转28067`; |

| 28067 | 在28066学飞躲强训代码改好后,重新规划训练步骤 |
| --- | --- |
| 第1步 | 随机出生位置:`随机位置扔木棒,重启`x200轮 & `左棒,重启`x100轮x1次 |
| 第2步 | 随机偏中出生:`扔木棒,即刻随机同向飞连飞x3次` x 100轮; |
| 结果 | 以上述步骤,训练得到FZ73; |

| 28068 | 触发canset再类比的proto总是只有`飞`; |
| --- | --- |
| 示图 | ![](assets/669_触发canset再类比的proto只有行为BUG.png) |
| 问题 | proto只有飞,导致抽象出的absCanset就只有飞; |
| 分析 | 导致抽象出的absCanset压根没有场景满足的可能; |
| 思路 | 尝试把cutIndex前段也拼接到proto中,这样就ok了; |
| 方案1 | 从solutionFo取前段+有反馈的feedbackAlg,生成protoFo; |
|  | 分析: 前段其实是pFo,所以从solutionFo取前段其实是不够真实的; |
|  | 结果: 但因为`不允许抽具象跨层`,所以solutionFo就是它的实际发生`95%` |
| 方案2 | 直接取pFo.realMaskFo,生成protoFo; |
|  | 分析: 此方案全是实际发生,但H任务的base是targetFo,而不是pFo; |
|  | 且pFo太抽象,如果pFo中取proto前段,那么类比后最终会在absCanset中 |
|  | 那么今后,这条absCanset,在判断条件满足很难成功,因为它的元素太抽象 |
|  | > 所以,原则上,尽量不要让跨抽具象层级的事发生 (迪米特法则); |
|  | 结果: 所以pFo虽然是绝对的实际发生部分,但不允许这么跨层使用它 `5%`; |
| 原则 | 方案中提到原则: 禁止跨层使用抽具象 (类似迪迷特法则); |
|  | 因为关系是就近的,跨层即使真实却没就近关系,其真实没法用 (没法判断); |
| todo | 选定方案1,在取proto的order方法中,加入前段部分 `T`; |
| 结果 | 已实现方案1,回测ok; |

总结: 本节改了测试步骤(支持模拟手动即时输出行为来训练),改了canset再类比proto只有飞的问题,并重新训练了FZ73,FZ73上再回测转n28p07;

***

## n28p07 测canset再类比很少 & S准确度很低
`CreateTime 2023.02.13`

| 28071 | canset再类比触发极少,查下原因 |
| --- | --- |
| 思路 | 经查代码,主要查下`test17:核实下,R和H任务...;` |
| 调试 | 经查原代码为S.status=actYes才执行canset再类比; |
| 修复 | 而实测中它是runing状态而不是actYes,所以兼容在runing时也执行 `T`; |

| 28072 | S的AIRank老是返回`左躲`方案 |
| --- | --- |
| 复现 | `FZ73,路偏上出生,左投木棒`; |
| 问题 | 左躲是不可能躲成功的,因为木棒就是从左到右扔出的; |
| 调试 | 经查,S的后段匹配度都很低(0.2最高); |
| 思路 | 可以尝试用S的有效性,S未必要执行完时才有效,有可能执行一步就有效; |
|  | 比如: [棒,飞,棒]可能执行飞一下,就躲成功了,而不是非要第3帧有反馈; |
| 反例 | 比如,左飞时,如果正好有别的上飞行为起到了作用,左飞S就能成为Canset; |
|  | 即使左飞S后段很稳定,也并非它有效,而它的`有效性`才能说明它没用; |
| 示例 | 参考28074,F1456的P是15,稳定性极高,但它是错误的,只是执行了飞而已; |
| 所以 | 中段有效性需做成单独竞争器,不能单纯用到前中后的相乘中 `转28081`; |

```c
//28074代码段: 以下为SolutionRanking执行后,从前13条中抽选 (顺序不变);
> F1456[A1414(高100,Y207,皮0,X2,Y距_偏上0.4_7,距122,X距352),A965(飞←),A1420(高100,Y207,皮0,Y距_偏上0.4_7,距69,X130,X距195)]
 综合排名:0 (前0.99 中0.19 后1.00) eff:{} sp:{1 = S0P15;}

> F1458[A1414(高100,Y207,皮0,X2,Y距_偏上0.4_7,距122,X距352),A965(飞←),A1420(高100,Y207,皮0,Y距_偏上0.4_7,距69,X130,X距195)]
 综合排名:1 (前0.99 中0.20 后1.00) eff:{} sp:{1 = S0P14;}

> F3223[A3193(高100,Y207,皮0,距113,X2,Y距_偏上0.2_24,X距326),A965(飞←),A3199(高100,Y207,皮0,距0,Y距_偏上0.2_24,X324,X距-25)]
 综合排名:2 (前0.95 中0.18 后1.00) eff:{} sp:{1 = S0P1;}

> F3385[A3360(高100,Y207,皮0,距129,X2,Y距_偏上0.2_24,X距376),A965(飞←),A3366(高100,Y207,皮0,X374,距0,Y距_偏上0.2_24,X距-25)]
 综合排名:3 (前0.89 中0.12 后1.00) eff:{} sp:{}

> F982[A943(高100,Y207,皮0,X2,距122,Y距_偏上0.8_-17,X距351),A946(飞↗),A949(高100,Y207,皮0,Y距_路上1.1_-38,距113,X55,X距319)...
 综合排名:13 (前0.91 中0.00 后1.00) eff:{} sp:{1 = S0P1;}
```

| 28075 | BUG_canset所在的pFo.effDic全是空 |
| --- | --- |
| 问题 | 参考28074代码段,发现所有pFo下的effectDic全是{}; |
| 结果 | 在修复28076后,发现此处BUG也没了,看来此BUG不存在 `T`; |

| 28076 | BUG_TCEffect()中,对demand下所有pFo都统计有效性 |
| --- | --- |
| 问题 | 比如怕光虫,我们用灯能是退它,但它对别的虫子咬人是无效的; |
|  | 如果我们把光虫的canset记录到咬人虫下面,是无效的; |
| 结果 | 把TCEffect.rEffect下改为仅对取得canset的pFo有效 `T`; |

| 28077 | BUG_撞到后也触发了构建canset及canset外类比; |
| --- | --- |
| 现代码 | 1. 在pFo的预测forecast_Single(),触发了pushFrameFinish; |
|  | 2. 在pushFrameFinish中未判断pFo的状态,就直接构建了canset及再类比; |
| 调试 | 经调试,撞到和未躲成功时,pFo的状态不同,如下: |
|  | 状态1: pFo的下帧(或mv末帧)未发生时,状态为TIStatus_OutBackNone |
|  | 状态2: pFo的mv末帧发生时,状态为TIStatus_OutBackSameDelta; |
| 修复 | 在pushFrameFinish中判断:只有情况1时才生成canset及外类比 `T` |
| 另外 | 本表BUG仅针对R任务,H任务需要等执行到时再看有没类似BUG; |

本节做了2.5件事如下 (其中第3条有半件未完成):
1. TCEffect改为仅对basePFo统计有效,而不是所有rDemand下的所有pFo;
2. 28072测得S未能越来越准,并制定28081`S越来越准`的迭代计划;
3. Canset再类比的触发时机和条件判断;
  * R任务已完成 (参考28077);
  * 对H任务的支持待test17触发时再继续 (未完成);

***

## n28p08 使S竞争越来越准:`整体分析 + 前段部分`
`CreateTime 2023.02.13`

在28072的S不准确的问题分析,最终得出S未能越来越准的问题,所以本节对S的自由竞争,细化拆分,并回测下S可以实现越来越准;

| 28080 | 通过向性分析本节基础支撑 |
| --- | --- |
| 认知 | 认知的向性是:右为主,上为辅; |
| 决策 | 决策的向性是:下为主,左为辅; |
| 分析 | 而本节主要针对`决策的向性`,下主,左辅; |
| 结论1 | 所以认知阶段的三次竞争是右向的,即: 主微宏:V->A->F三段,辅抽象; |
| 结论2 | 而决策阶段的三次竞争是下向的,即: 主具象Canset,辅:后->中->前三段; |
| 结果 | 关于认知和决策阶段的三次竞争: `转28082`; |

| 28081 | cansetRank竞争器细化迭代-方案制定; |
| --- | --- |
| 方案 | 取canset时,canset间竞争机制彻底拆分迭代下: |
|  | 1. 前段每帧都要做概念抽具象间`强度与匹配度`综合竞争; |
|  | 2. 后段要做`匹配度与稳定性`综合竞争; |
|  | 3. 中段要做有效性竞争; |
| 结果 | 本表是比较初级的想法,不够成熟,继续深入分析: `转28082`; |

| 28082 | 入阶段竞争因子总结 & 出阶段竞争因子分析 |
| --- | --- |
| **入阶段** | **在认知阶段,尤其是识别Recognition阶段,有多次竞争如下:** |
| V | 相近度排序 (前20%条); |
| A | 衰减后匹配度*衰减后引用强度 (前content长度x2条); |
| F | 衰减后匹配度*衰减后引用强度 (前10条); |
| **出阶段** | **在决策阶段,尤其是求解Solution阶段,也需要多次竞争如下:** |
| 前 | 用每帧在其对应的matchAlgs中的排名竞争 (取前20%); |
| 中 | 用衰减后稳定性*衰减后有效率 (取前20%); |
| 后 | R都一样(同是避免R任务的mv带来的价值),H任务的目标却不一样,如下: |
|  | 对targetAlg.conAlgs做衰减后匹配度*衰减后强度竞争 (取前20%); |
| 原则1 | **前段每帧的alg在对应的matchAlgs中的排名,来做竞争(废)** |
|  | > 后面实践中,实际上用了抽具象强度,而不是复用matchAlgs的排名; |
| 原则2 | **中后段还未发生,是无法判断匹配度的 (废);** |
|  | > 后面实践中,实际上后段用了匹配度 (未发生也有match与canset的匹配度); |

| 28083 | 制定前段竞争方案 |
| --- | --- |
| 方案1 | **用每帧在其对应matchAlgs的包含排名来竞争 (参考28082-前)** |
| 分析 | 需要从proto取得matchAlgs再判断包含cansetAlg; |
|  | > 其实就是判断proto抽象指向canset呗 `转方案2`; |
| 方案2 | **参考条件满足代码:用protoAlg到cansetAlg的强度和匹配度来竞争;** |
| 分析 | "条件满足"决定了此处protoAlg到cansetAlg绝对有关联; |
|  | > 所以,protoAlg到canset的指向强度,和匹配度都可以复用; |
|  | 结果: 用protoAlg到cansetAlg的衰减强度*衰减匹配度来竞争; |
|  | 问题: protoAlg和cansetAlg的抽具象强度永远是1,因为proto很难重复; |
|  | 修改: 所以此处强度改为与以往一样的,refStrong被引用强度吧; |
| 方案3 | **用pFoOrRegroupFo.conAlgs的强度和匹配度来竞争;** |
| 优点 | 这么做肯定会留有方案结果,因为只要有cansets,就会有竞争靠前的; |
| 缺点 | canset未必是pFo的具象,还是方案2更直接可靠且可复用"条件满足"代码; |
| 结果 | **根据上述分析,选定方案2,实践转28084** |

| 28084 | 前段竞争-代码实践-TODOLIST |
| --- | --- |
| 1 | compareCansetFo更名为getSolutionModel并移至TCSolutionUtil `T` |
| 2 | 将cansetFilterV2废弃,过滤器整合到getSolutionModel()中 `T` |
| 3 | 在getSolutionModel()中计算前段时,过滤掉条件不满足 `T`; |
| 4 | 写getMatchAndStrongByFrontIndexDic,计算竞争值(匹配度,强度) `T`; |
| 5 | 写AIRank.solutionFrontRank`衰减强度值*衰减匹配度`新排名器 `T`; |
| 6 | 写前段竞争后,过滤仅保留前20% `T`; |

| 28085 | BUG_测得前段refStrong总是1 |
| --- | --- |
| 原因 | 因为cansetFo在S最终胜利激活后,也没更新它的强度,所以一直是0; |
| 修复 | 在Solution最终激活canset后,将其前段引用强度更新+1 `T`; |

| 28086 | 问题_前段强度竞争值依据不该用refStrong问题 |
| --- | --- |
| 说明 | S竞争明明是在搞canset竞争,但却用refStrong这不合理; |
| 原因 | 1. 说白了,这里是想知道哪个canset更适合搞定matchFo的问题; |
|  | 2. 而不是从微观应该识别哪个宏观,所以不该用refStrong; |
| 原则 | 认知阶段强度竞争用refStrong,决策阶段强度竞争用conStrong`不确定`; |
| todo1 | 改为用matchFo和cansetFo的前段,取其抽具象强度值 `T`; |
| todo2 | 在最终激活canset后,将其conPorts强度和absPorts强度全更新+1 `T` |

本节整体分析了S竞争越来越准的问题,并且写了前段部分:
1. 强度竞争值用matchAlg和cansetAlg的抽具象强度为依据;
2. 匹配度竞争值用protoAlg和cansetAlg的抽具象匹配度为依据;
3. 新写AIRank.solutionFrontRank()做排名器;

***

## n28p09 使S竞争越来越准:`中段部分 + 后段部分`
`CreateTime 2023.02.18`

上节做了整体分析和前段部分,本节做中断和后段部分;

| 28091 | 中段-方案规划 |
| --- | --- |
| 参考 | 28082-中段未发生不能用匹配度,要用衰减后稳定性*衰减后有效率 |
| todo1 | 参考原本计算稳定性和有效率的代码 `T`; |
| todo2 | 写中段竞争器,并应用 `T`; |

| 28092 | 后段-方案规划 & 代码实践 |
| --- | --- |
| 分析 | 仅H有后段,后段即targetAlg,targetAlg就是最直接的需求; |
| 问题1 | 而它的具象conPorts的algs很繁杂,需要择优; |
| 思路 | 即根据targetAlg.conPorts的强度和匹配度来做为竞争力值计算依据; |
| 问题2 | 为保证cansets中找出更优的,所以必须根据竞争值来做cansets排名; |
| 思路 | 还是放到solutionBackRank()排名器来做,根据竞争值衰减综合算出; |
| 方案 | > 根据问题1&2: 以targetAlg的具象强度与匹配度为竞争值依据; |
|  | > 然后写solutionBackRank()来计算排名,最后保留20%的cansets; |
| 优点 | 即保证`后段的强度匹配度有用`,又保证`绝对找出cansets中更好部分`; |
| 实践 | 以上方案可选用,实践在本表下方继续: |
| todo1 | 计算后段匹配度竞争值到SolutionModel模型下 `T`; |
| todo2 | 计算后段强度竞争值到SolutionModel模型下 `T`; |
| todo3 | 写solutionBackRank()竞争器 `T`; |
| todo4 | 写最终激活canset后,使后段抽具象强度+1 `T`; |

***

## n28p10 使S竞争越来越准:`测试`
`CreateTime 2023.02.19`

| 28101 | 回测项 |
| --- | --- |
| 1 | 回测分析下,有效率是不是应该是后段的事儿? |

| 28102 | 训练步骤 (28067) |
| --- | --- |
| 第1步 | 随机出生位置:`随机位置扔木棒,重启`x200轮 & `左棒,重启`x100轮x1次 |
| 第2步 | 随机偏中出生:`扔木棒,即刻随机同向飞连飞x3次` x 100轮 x 3次; |
| BUG1 | R任务的Cansets为0条,经查日志,有生成Canset给pFo,但取时却是0条; |

<br><br><br><br><br>
