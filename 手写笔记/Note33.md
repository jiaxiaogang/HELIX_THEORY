# (觅食 & 飞躲 & 踢搬运)三项的多向连续训练,以及三项融合训练

在前面,已经学会搬运,且会用搬运来踢坚果到路上,至此所有单轮的训练项目全部通过了,以下开始对这些项目进行连续行为训练,以及融合在一起训练等;

***

<!-- TOC -->

- [(觅食 & 飞躲 & 踢搬运)三项的多向连续训练,以及三项融合训练](#觅食--飞躲--踢搬运三项的多向连续训练以及三项融合训练)
  - [n33p01 回顾训练觅食](#n33p01-回顾训练觅食)

<!-- /TOC -->

***

## n33p01 回顾训练觅食
`CreateTime 2024.08.09`

训练就两个方法: 一是教的多,二是练的多;

| 33011 | 尝试训练觅食-初步规划大岗 |
| --- | --- |
| 1. 学飞 | 8个方向一步远位置各扔下无皮果,引至吃掉 |
| 2. 试错 | 8个方向一步远位置各扔下无皮果,点击饥饿,试错尝试; |

| 33012 | 尝试训练觅食-训练方法分析 |
| --- | --- |
| 原则 | **训练就俩方法: 一是教,二是练**; |
| 教 | 即: 最基本的经历(比如: 能够抽象出无距方向坚果的场景 & 在反射反应中各个方向都飞过); |
| 练 | 即: 先给个简单的的场景(比如: 坚果扔近些,让它试错,让正确飞行方向的Canset能优胜出); |

| 33013 | 尝试训练觅食-学无距有向果场景 |
| --- | --- |
| 目标 | 先习得`8个方向无距坚果`的场景; |
| 回顾 | 经查871,882,913,这前三步的训练,都没有各方向无皮果训练的步骤; |
| 步骤 | **无皮学饿: 认知模式(`饿(持续饿感3次),扔随机无皮坚果,不吃,又饿`x50轮);** => |
| 强训 | 参考RLT工具中现在已经有`学饿`和`学吃`两个强训项 (参考28172-第1步&第2步); |

**小结: 上面三表,从大岗到实际尝试`训练觅食`,测得时序识别同质化严重的问题,转下表先修一下;**

| 33014 | BUG: 测得时序识别结果同质化严重 |
| --- | --- |
| 描述 | 在上表训练中,时序识别结果20条全是`[饿]->{更饿}`; |
| 问题 | 而我们希望它能训练出`无距有向果`场景,现在连识别都识别不到,谈何抽象出`无距有向果`场景呢? |
| 白话 | 说白了,这会导致智能体刻板固化,不易接受新事物(新场景难出头,更难类比抽象); |
| 说明 | 它识别的全是[饿]->{更饿},并且它们强度一个比一个强,所以`带方向果`的永无出头之日; |
| 分析 | 现在时序没有防重功能,导致同质化严重,同样的饿->更饿能占满20条,即因为此; |
| 方案1 | 场景时序加上全局防重功能 `95%`; |
|  | > 全局防重倒是简单可行,只需要参考当时概念全局防重: 在构建时,优先取本地已有的一模一样的时序即可; |
| 方案2 | 同质时序在识别结果中互斥 `5%`; |
|  | > 互斥很难判断,比如indexDic全含,且有共同的抽具象关系,算互斥吗?或者说相似度达到怎样算互斥? |
| 实践 | 暂选定方案1进行实践: 参考概念全局防重,为场景时序构建时,也加上相应的防重功能即可; |
| 结果 | 经查,原本就有防重功能,只是构建`最具象时序protoFo`时,有些没调用防重方法,全改成调用即可 `T`; |

**小结: 33014中,把时序识别同质化严重的问题修了下 (打开了protoFo构建时的全局防重),下表继续回归训练觅食;**

| 33015 | FZ981-尝试训练觅食-学无距有向果场景B |
| --- | --- |
| 说明 | 因为protoFo未防重的BUG影响到FZ97,所以本表重新从第1步训练FZ98; |
| FZ981 | 用强训工具训练`无皮学饿` (参考33013-步骤) `存为FZ981`; |
| 训练步骤 | `饿,扔随机坚果,不吃,又饿` x 50轮; |
| 回测 | `FZ981,饿,随便扔个果`,观察概念识别和时序识别结果,如下: |
|  | 1. 概念识别结果中: 无向果 或 无距果 两种都有了; |
|  | 2. 时序识别结果中: 无向果场景 或 无距果场景 或 无距无向果场景 三种都有了 (参考33015-代码段1); |
| 问题 | 虽然A和F识别都ok了,不过时序识别在二次过滤后: 未识别到`无距有向果场景`结果 (参考33015-代码段2); |
| 结果 | 将问题修复后,重新训练FZ981完成 `T`; |

```java
33015-代码段1: 训练日志分析 ==> 这个代码段主要是33015-回测的从时序识别日志中摘出;
经查1: 从时序识别结果看: protoFo:[饿果]-> 和 protoFo:[饿果果]-> 没有识别结果 (时序识别到0条);
经查2: 反而,饿果果果 & 饿果果果果 & 饿果果果果果 & 饿果果果果果果 & 饿果果果果果果果 & 饿果果果果果果果饿果 & 饿果果果果果果果饿果果 ... 都有识别结果;
    > 应该是因为只识别有mv指向的结果,而连续视觉中,只要更饿发生了,就肯定已经看了3帧以上的`果`了,前两帧时,还没更饿,所以也没法识别到,这是正常的;

成果1: 像无向果场景也可以识别到 => "2. P强度:(106)    > F1951[M1{↑饿-16},A1950(距90,果),A1950(距90,果),A1950(距90,果)]->{-6.54}";
成果2: 像无距果场景也可以识别到 => "0. P强度:(2060)    > F31[A30(向189,果),A30(向189,果),A30(向189,果),A30(向189,果)]->{-4.29}";
成果3: 像无向无距果场景也可以识别到 => "3. P强度:(289)    > F1654[M1{↑饿-16},A49(,果),A49(,果),A49(,果)]->{-2.49}";
结果: 如上日志3个成果可见,时序识别已经ok了,无距有向果场景,已经抽象到了,也能识别到了 `T`;
```

```java
33015-代码段2: 测得识别问题 ==> 在时序识别二次过滤后,没有`无距有向果场景`的结果;
时序二次过滤后条数: 原20 剩5 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
	1. F956[M1{↑饿-16},A932(距90,向161,果),A932(距90,向161,果),A932(距90,向161,果)]
	2. F935[M1{↑饿-16},A932(距90,向161,果),A932(距90,向161,果),A932(距90,向161,果)]
	3. F443[M1{↑饿-16},A436(距67,向174,果),A436(距67,向174,果),A436(距67,向174,果),A436(距67,向174,果),A436(距67,向174,果),A436(距67,向174,果),A436(距67,向174,果)]
	4. F52[M1{↑饿-16},A51(向182,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果)]
	5. F28[M1{↑饿-16},A12(距100,向182,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果)]
结果: 经查是因为二次过滤算法,只针对PJ似层,把交层全给过滤掉了 `已修复 T`;
```

**小结: 以上33015做了第1步FZ981学饿,并且已经可以顺利抽象出`无距有向果场景`,下面继续在这个基础上做第2步`学吃训练`**

| 33016 | FZ982-尝试训练觅食-各方向学飞吃 |
| --- | --- |
| FZ982 | 学一下向8个方向的飞,和靠飞可以改变距离,解决吃到坚果的距离问题,存为FZ982 |
| 步骤初定 | 手动训练: 8个方向一步远位置各扔下无皮果,引至吃掉 |
| 步骤分析 | 刚开始还是多做些原始积累,用强化训练来跑比较好,并且手把手教的太多也不太好,像婴儿一样让它自己学步比较好; |
| 训练步骤 | `饿,扔附近坚果,随机连飞3下(如飞中吸吮反射)` x 100轮 (参考28173-2学飞); |
| 重点关注 | 打出flt日志,观测在预测会更饿,然后飞吃到坚果后,习得newRCanset; |
| 结果 | 经查日志,newRCanset执行了很多,因为是认知模式,没有跑absRCanset,等FZ983时,再测absRCanset; |

**小结: 做了FZ982训练完成,下面做FZ983试错训练;`**

| 33017 | FZ983-尝试试错训练-各方向自行飞吃 |
| --- | --- |
| FZ983 | 8个方向方向扔下无皮果,然后让它自己决策行为飞吃; |
| 训练步骤1 | 附近一飞距离手动扔无皮果,然后观察它能不能越来越准确的飞正确方向; |
| 训练步骤2 | 远距离手动扔无皮果,然后观察它能不能自行准确的飞吃到坚果; |
| 重点关注 | 1.观察下各个RCanset的SP值; 2.观察下在求解时RCanset正确时,能触发类比并生成AbsRCanset; |
| 训练记录 | 第1次: 饿,扔右上无皮果,它自行右下飞,上飞,上飞,吃了果; |
|  | 第2次: 饿,扔上方无皮果,它自行上飞,吃了果; |
| 明日 | 重点观察下,让sceneFrom和sceneTo都是带无距有向果的场景,不然正确再多,也只是蒙中了而已; |

```java
33018-BUG回测发现RCanset跳过了飞 `T 不是BUG,见结果`
=============================== 5 rSolution ===============================
任务源:饿 protoFo:F5923[M1{↑饿-16},A3442(向135,距12,果),M1{↑饿-16},A3442(向135,距12,果)] 已有方案数:0 任务分:-3.93
第7步 R排除Infected传染掉的:53
R0. I<F1418 F3788[↑饿-16,2果,飞↙,2果]> {0 = 0;1 = 1;2 = 3;}  H4N0:(分:1.00) [CUT:3=>TAR:4]
R1. I<F1568 F3789[↑饿-16,3果,飞↙,3果]> {0 = 0;1 = 1;2 = 3;}  H4N0:(分:1.00) [CUT:3=>TAR:4]
复现: FZ982,饿,附近扔无皮果 -> 然后看rSolution日志即可看到;
说明: 如上日志,所有RCanset的CUT就是第四帧(下标3),而第四帧就是最后一帧,即它没行为化任何东西,直接等待末帧mv自然不发生;
问题: 这显然不对,这种RCanset没有飞行,是不可能成功的,它的前段条件判断有问题;
回顾: 上次原本就把前段条件满足给弃掉了,所以这个BUG我们正好想一下,是否应该重新打开前段条件满足 (上回是用场景满足替代了前段条件满足);
思路: 查下,为什么这里的CUT是3,它应该是1才对吧;
    > 日志1. sceneFrom: F1568[M1{↑饿-16},A1563(距45,果),A1563(距45,果)]
    > 日志2. cansetFrom: F3789[M1{↑饿-16},A1563(距45,果),飞↙,A1563(距45,果)]
说明: 如上日志可见: sceneFrom中确实发生两帧无皮果,所以对应到cansetFrom确实是在方向之后了,没啥BUG;
    > 日志3. sceneFrom: F1418[M1{↑饿-16},A51(,果),A51(,果)]
    > 日志4. cansetFrom: F1841[M1{↑饿-16},A51(,果),A51(,果),飞↘,A1838(距7,向286,果)]
说明: 如上日志可见: 也有些sceneFrom的cansetFrom中的飞是在CUT之后的 (即可以正常输出飞行行为的);
结果: 所以,此BUG不算BUG,只是有一些无效的canset还没被否掉罢了,等它们都被否了,自然就有可以输出飞行行为的canset可被激活 `T 不是BUG,不必修,继续33017试错训练`;
```

| 33019 | BUG2-Root无法持续激活,导致来不及p反省负SPEFF,就不激活了 |
| --- | --- |
| 起因 | 试错训练时,无向场景,下的cansetFrom应该被SP否掉,直至无法激活; |
|  | 但训练时: RCanset:F1418被激活许多次,也没能飞对方向解决饥饿问题,但P反省的负SPEFF日志一直没执行到; |
| 说明 | 现在在持续视觉后,其实像[无皮果,飞,吃]这样的Canset里的这几帧都很容易被反馈到,但它即使全反馈了也未必有效; |
|  | 比如: 一个无向场景,它下面的Canset可能飞向任何方向,但这个方向是错误的,此时即使全反馈到Canset执行完成,也无效; |
| 问题 | 这导致一个Root即使R帧推进再顺利,P末帧反馈也无效,但现在的BUG是`它没有执行到P反省负SPEFF`; |
| 调试 | Root1激活后,执行一两轮行为化,大概能飞一下,然后就成了被传染状态,在计算任务进度分时,传染状态会跳过; |
|  | 导致,Root1被传染了,它的进度分是0,也就没啥竞争力,导致无法激活了,此时还没到执行p反省的时候,所以没法计负; |
|  | 导致,试错训练中,无论怎么跑,它都`没起到试错的作用`; |
| 日志 | R行为化中间帧下标 (3/5) 飞↑ from时序:F2236[↑饿,果,果,飞↑,A2233(果)] fromDemand:F8414 |
|  | R行为化中间帧下标 (4/5) A2233(距0,向103,果) from时序:F2236[↑饿,果,果,飞↑,A2233(果)] fromDemand:F8414 |
|  | R行为化末帧下标 (4/4)  from时序:F6341[M1{↑饿-16},A51(,果),飞↑,A51(,果)] fromDemand:F8428 |
|  | 说明: Root任务F8414激活两次后,就没再激活了; |
| 思路 | 说白了,还是Root任务的竞争问题,以前的做法是:`任务1静默等待时,会执行任务2`; |
|  | 问题-而这一做法导致饥饿Root1静默了,饥饿Root2继续尝试,依此类推,没一个Root能跑到P反省负SPEFF; |
| 方案1 | 同区任务应该互斥,非同区任务不排斥; |
|  | 1. 情况1-即一个饥饿任务在静默等待时,别的饥饿任务也不应该执行; |
|  | 2. 情况2-而饥饿任务在静默等待时,非饥饿的任务应该可以先执行; |
| 方案2 | 所有任务都不排斥; |
|  | 1. 在此方案下,如果饥饿任务最迫切并竞争取胜激活了,并且此任务在静默等待状态,那么别的任务全等着不允许执行; |
|  | 2. 除非`危险任务`更强,它最迫切并取胜激活了,才可以跨过饥饿,先执行危险任务; |
| 抉择 | 方案1看似更应对所有情况,实际方案2更简单直白,方案2也可以应对所有情况,所以先选用方案2; |
|  | 如果以后方案2发现不够用,再回来考虑方案1; |
| 实践 | TODO1-在Canset被传染后,或者状态非ActYes或Runing时,也计进度分 `T`; |
|  | TODO2-在TCPlan中,如果Root1是静默状态(或者被传染状态),那么这轮TO线程就空转啥也不跑; |

<br><br><br><br><br>
