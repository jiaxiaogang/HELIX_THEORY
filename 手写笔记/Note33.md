# (觅食 & 飞躲 & 踢搬运)三项的多向连续训练,以及三项融合训练

在前面,已经学会搬运,且会用搬运来踢坚果到路上,至此所有单轮的训练项目全部通过了,以下开始对这些项目进行连续行为训练,以及融合在一起训练等;

***

<!-- TOC -->

- [(觅食 & 飞躲 & 踢搬运)三项的多向连续训练,以及三项融合训练](#觅食--飞躲--踢搬运三项的多向连续训练以及三项融合训练)
  - [n33p01 回顾训练觅食](#n33p01-回顾训练觅食)

<!-- /TOC -->

***

## n33p01 回顾训练觅食
`CreateTime 2024.08.09`

训练就两个方法: 一是教的多,二是练的多;

| 33011 | 尝试训练觅食-初步规划大岗 |
| --- | --- |
| 1. 学飞 | 8个方向一步远位置各扔下无皮果,引至吃掉 |
| 2. 试错 | 8个方向一步远位置各扔下无皮果,点击饥饿,试错尝试; |

| 33012 | 尝试训练觅食-训练方法分析 |
| --- | --- |
| 原则 | **训练就俩方法: 一是教,二是练**; |
| 教 | 即: 最基本的经历(比如: 能够抽象出无距方向坚果的场景 & 在反射反应中各个方向都飞过); |
| 练 | 即: 先给个简单的的场景(比如: 坚果扔近些,让它试错,让正确飞行方向的Canset能优胜出); |

| 33013 | 尝试训练觅食-学无距有向果场景 |
| --- | --- |
| 目标 | 先习得`8个方向无距坚果`的场景; |
| 回顾 | 经查871,882,913,这前三步的训练,都没有各方向无皮果训练的步骤; |
| 步骤 | **无皮学饿: 认知模式(`饿(持续饿感3次),扔随机无皮坚果,不吃,又饿`x50轮);** => |
| 强训 | 参考RLT工具中现在已经有`学饿`和`学吃`两个强训项 (参考28172-第1步&第2步); |

**小结: 上面三表,从大岗到实际尝试`训练觅食`,测得时序识别同质化严重的问题,转下表先修一下;**

| 33014 | BUG: 测得时序识别结果同质化严重 |
| --- | --- |
| 描述 | 在上表训练中,时序识别结果20条全是`[饿]->{更饿}`; |
| 问题 | 而我们希望它能训练出`无距有向果`场景,现在连识别都识别不到,谈何抽象出`无距有向果`场景呢? |
| 白话 | 说白了,这会导致智能体刻板固化,不易接受新事物(新场景难出头,更难类比抽象); |
| 说明 | 它识别的全是[饿]->{更饿},并且它们强度一个比一个强,所以`带方向果`的永无出头之日; |
| 分析 | 现在时序没有防重功能,导致同质化严重,同样的饿->更饿能占满20条,即因为此; |
| 方案1 | 场景时序加上全局防重功能 `95%`; |
|  | > 全局防重倒是简单可行,只需要参考当时概念全局防重: 在构建时,优先取本地已有的一模一样的时序即可; |
| 方案2 | 同质时序在识别结果中互斥 `5%`; |
|  | > 互斥很难判断,比如indexDic全含,且有共同的抽具象关系,算互斥吗?或者说相似度达到怎样算互斥? |
| 实践 | 暂选定方案1进行实践: 参考概念全局防重,为场景时序构建时,也加上相应的防重功能即可; |
| 结果 | 经查,原本就有防重功能,只是构建`最具象时序protoFo`时,有些没调用防重方法,全改成调用即可 `T`; |

**小结: 33014中,把时序识别同质化严重的问题修了下 (打开了protoFo构建时的全局防重),下表继续回归训练觅食;**

| 33015 | 尝试训练觅食-学无距有向果场景B |
| --- | --- |
| 说明 | 因为protoFo未防重的BUG影响到FZ97,所以本表重新从第1步训练FZ98; |
| 步骤1 | 用强训工具训练`无皮学饿` (参考33013-步骤) `存为FZ981`; |
| 回测 | `FZ981,饿,随便扔个果`,观察概念识别和时序识别结果,如下: |
|  | 1. 概念识别结果中: 无向果 或 无距果 两种都有了; |
|  | 2. 时序识别结果中: 无向果场景 或 无距果场景 或 无距无向果场景 三种都有了 (参考33015-代码段1); |
| 问题 | 虽然A和F识别都ok了,不过时序识别在二次过滤后: 未识别到`无距有向果场景`结果 (参考33015-代码段2); |

```java
33015-代码段1: 训练日志分析 ==> 这个代码段主要是33015-回测的从时序识别日志中摘出;
经查1: 从时序识别结果看: protoFo:[饿果]-> 和 protoFo:[饿果果]-> 没有识别结果 (时序识别到0条);
经查2: 反而,饿果果果 & 饿果果果果 & 饿果果果果果 & 饿果果果果果果 & 饿果果果果果果果 & 饿果果果果果果果饿果 & 饿果果果果果果果饿果果 ... 都有识别结果;
    > 应该是因为只识别有mv指向的结果,而连续视觉中,只要更饿发生了,就肯定已经看了3帧以上的`果`了,前两帧时,还没更饿,所以也没法识别到,这是正常的;

成果1: 像无向果场景也可以识别到 => "2. P强度:(106)    > F1951[M1{↑饿-16},A1950(距90,果),A1950(距90,果),A1950(距90,果)]->{-6.54}";
成果2: 像无距果场景也可以识别到 => "0. P强度:(2060)    > F31[A30(向189,果),A30(向189,果),A30(向189,果),A30(向189,果)]->{-4.29}";
成果3: 像无向无距果场景也可以识别到 => "3. P强度:(289)    > F1654[M1{↑饿-16},A49(,果),A49(,果),A49(,果)]->{-2.49}";
结果: 如上日志3个成果可见,时序识别已经ok了,无距有向果场景,已经抽象到了,也能识别到了 `T`;
```

```java
33015-代码段2: 测得识别问题 ==> 在时序识别二次过滤后,没有`无距有向果场景`的结果;
时序二次过滤后条数: 原20 剩5 >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
	1. F956[M1{↑饿-16},A932(距90,向161,果),A932(距90,向161,果),A932(距90,向161,果)]
	2. F935[M1{↑饿-16},A932(距90,向161,果),A932(距90,向161,果),A932(距90,向161,果)]
	3. F443[M1{↑饿-16},A436(距67,向174,果),A436(距67,向174,果),A436(距67,向174,果),A436(距67,向174,果),A436(距67,向174,果),A436(距67,向174,果),A436(距67,向174,果)]
	4. F52[M1{↑饿-16},A51(向182,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果)]
	5. F28[M1{↑饿-16},A12(距100,向182,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果),A14(距121,向170,果)]
```

<br><br><br><br><br>
