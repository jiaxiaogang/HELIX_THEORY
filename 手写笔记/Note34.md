# 测试推进细节修正的问题，并整理推进(觅食 & 飞躲 & 踢搬运)三项的多向连续训练,以及三项融合训练

在前面,已经学会搬运,且会用搬运来踢坚果到路上,至此所有单轮的训练项目全部通过了,以下开始对这些项目进行连续行为训练,以及融合在一起训练等;

***

<!-- TOC -->

- [测试推进细节修正的问题，并整理推进(觅食 & 飞躲 & 踢搬运)三项的多向连续训练,以及三项融合训练](#测试推进细节修正的问题并整理推进觅食--飞躲--踢搬运三项的多向连续训练以及三项融合训练)
  - [n34p01 回测简化的嵌套关系、OutSPDic存取、新版Solution、CansetV3类比等](#n34p01-回测简化的嵌套关系outspdic存取新版solutioncansetv3类比等)
  - [n34p02 长字符串相似性识别（从稀疏粒度到特征）](#n34p02-长字符串相似性识别从稀疏粒度到特征)

<!-- /TOC -->

***

## n34p01 回测简化的嵌套关系、OutSPDic存取、新版Solution、CansetV3类比等
`CreateTime 2025.03.13`

| 34011 | 重新训练下三步,并存为FZ103（参考33132） |
| --- | --- |
| FZ1031 | 认知模式:`饿,扔随机坚果,不吃,又饿`x50轮 (RL工具跑:无皮学饿) (参考33013-步骤) `T`; |
| FZ1032 | 认知模式:`饿,扔附近坚果,随机连飞3下(如飞中吸吮反射)`x100轮 (RL工具跑:学吃) (参考28173-2学飞) `T`; |
| FZ1033 | 动物模式:`饿,某方向附近扔果` (注: 看它能不能自行飞吃到,如果飞错,也不要干预它,多试错训练几次); |

| 34012 | 训练中观察注意 |
| --- | --- |
| 测项1 | 观察新的构建Canset四处代码。 |
| 测项2 | 看下推举V3算法，能不能正常推举和构建映射等。 |
| 测项3 | 看下OutSPDic的存取。 |
| 测项4 | 看下新版Solution仅从F求解情况。 |
| 测项5 | 看下CansetV3类比器，能不能正常类比出结果。 |
| 测项6 | 递归更早前的测试项：看下hSolution还会不会总是无解了。 |
| 测项7 | 递归更早前的测试项：第3步试错训练,看`有向无距果场景`在不断竞争中SP浮现的怎么样; |

***

## n34p02 长字符串相似性识别（从稀疏粒度到特征）
`CreateTime 2025.03.14`

**34021、需求**
老同事的需求，想搞这样的数据库。在HE系统的数据库基础上分析如下（有些像加了解释性的CNN，也可以到网上自行找“CNN可解释性研究”，应该还有别的可行方案）。

**34022、数据库**
1. 稀疏码：一个字符串有一千字符，用这一千字符，生成1000个稀疏码（每个码必须是一个值类型）。
2. 稀疏索引：把各个稀疏码做成一个数组索引（按从小到大排序）。
3. 稀疏粒度：可以对长字符串按1/10，1/100，1/1000粒度去分别做多粒度分组。按1/10粒度，就是100字符一粒，用这一粒生成一个平均值，计为一条该粒度的稀疏码。
4. 特征：其实就是整个字符串，在该例中，计为：它的字符串特征（因为该例不涉及比如视觉那样的多特征，所以只需要走到特征这一级就够用了）。
5. 特征与稀疏码：一组稀疏码，组成一个特征（比如1/10粒度的特征就含10个稀疏码）。
6. 特征引用：每个特征引用了哪些稀疏码，比如1/10粒度时，有100个稀疏码，特征要分别与它的100个稀疏码创建一个关联（叫refPorts关联）（这个关联以后要用来做启发式搜索的）。
7. 关联强度：以后搜索时，每一次激活成功后，要对这个refPorts中记一次strong+1（也是以后用来搜索竞争用的）。

8. 另1、粒度关联：在1/10，1/100，1/1000各粒度产生出的稀疏码间，要建立关联，比如：一千字符，产出1/10粒度稀疏10个，它的每块分别与1/100粒度产生的100个中的10个码建立粒度关联splitPorts。
9. 另2、特征错位：另外为了准确度，也可以做错位层（即以0.5个粒度进行）（这条也是为了性能，因为粗粒度时，筛选的越准，它后面性能就越好）。
10. 另3、再后面的概念、时序、价值，这些在该需求不涉及，砍掉。

**34023、工作步骤**
1. 输入长字符串。
2. 按从粗到细粒度，分别拆分成稀疏码（如1/10，产出10个稀疏码）。
3. 每个产出码，都在各自粒度的索引序列中，可以向上下相近的值扩展30%（比如现在平均值是666，那么找到索引后，分别向从小大到的索引序列两测扩15%）（相当于找30%的值相近度）。
4. 然后分别通过这些稀疏码的refPorts找对应特征索引（记住，此时并不激活特征，只是取出refPorts索引而已，性能上没问题）。

5. 根据各粒度取到的refPorts，计算匹配度（注意：稀疏码索引时，就已经知道相近度了，这是微观相似度，到宏观特征的相似度由乘积获得）。
6. 通过refPorts取出强度（过去激活次数）。
7. 单粒度内通过refPorts取到目标的次数（因为单个粒度也有多个码，索引时可以指向同一个refPort.target特征多次）。
8. 多粒度间通过refPorts取到目标的次数（多个粒度取refPort.target特征虽然各自在不同粒度上，但它们有splitPorts粒度关联，可以来判断refPort.target是不是指向同一个特征）。
9. 取次数其实是在取交（相当于缩小范围，即：每一新取refPorts时，相当于直接在上一轮的结果中取）。

10. 竞争：根据以上匹配度、强度、索引到目标次数，综合竞争（找出各粒度都比较匹配的特征结果）。
11. 结果：最后得到结果仍是数组，并且是有相似度，且在一级级向细粒度上解析，可以完全还原它的内容，即：具备可解释性）。

**小结：以上大概讲了从稀疏码到特征的表征和识别方式。**

| 34024 | 用图表示稀疏码到特征的流程 |
| --- | --- |
| 示图 | ![](assets/734_稀疏码到特征.png) |
| 步骤1 | 如图，我们从粗粒度开始索引，它因为粒度粗（所以refPorts结果少），再加上扩30%的索引（ref结果会多些，但因为粒度粗，在可接受范围），做为一级结果。 |
| 步骤2 | 然后分两条路径：一条是根据取到的粗结果特征，向细粒度找splitPorts。另一条从细粒度稀疏码，向refPorts找细粒度特征。 |
| 步骤3 | 两条路径的结果取交集（或结果计数，计数多的更准确），然后根据匹配度竞争，再保留可接受数量的二级结果。 |
| 步骤5 | 再分两条路径：二级结果向splitPorts取，三级粒度稀疏码向refPorts取。 |
| 步骤6 | 再两条路径的结果取交集（或结果计数，计数多的更准确），然后根据匹配度竞争，再保留可接受数量的三级结果。 |
| 结果 | 像如图中，一级取到4条(ABCD)，二级2条(B9,D9)，三级1条(D99)，当然图只是个示意，真要跑的是九格全跑，不可能只跑第9格。 |

**小结：34024中，通过示图详细说明了从稀疏码到特征的识别过程。**

| 34025 | 非视觉中心错位，导致识别不准确的问题。 |
| --- | --- |
| 问题说明 | 识别时，原感官数据有错位问题，比如视觉往往不在视觉中心，导致错位，导致识别不准。 |
| 思路分析 | 当识别有价值影响（值得关注）的信号（如危险）时（此时已经有了任务），它正视目标然后能实现更准确识别，并解决任务。 |
| 正面解答 | 那这个：”正视目标”本身就是解决任务的第一个步骤而已，即：我们是为了解决任务，才正视目标，识别目标，精准解决任务。 |
| 反面解答 | 而不是为了能解决识别的非视觉中心错位问题，而专门去实现正视目标，或者平移图像实现识别。 |
| 总结 | 即：此问题，融入到整个思维系统中去解决了，而不是通过感官算法解决（即我老以前说的，脖子动是行为，而不是主动视觉的功能）。 |

**小结：34025中，描述了被动视觉是怎样实现正视的，解答了非视觉中心导致的识别不准确问题。**
**总结：当前he4o的v2版本不做多码特征，此笔记中多码特征部分，和splitPorts粒度关联并未工程化，但整个做法与以往HE的做法是同源的。**

***

<br><br><br><br><br>
