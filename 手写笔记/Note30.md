# 回测防撞训练继续觅食训练

***

<!-- TOC -->

- [回测防撞训练继续觅食训练](#回测防撞训练继续觅食训练)
  - [n30p01 回测防撞训练](#n30p01-回测防撞训练)
  - [n30p02 回测觅食训练](#n30p02-回测觅食训练)

<!-- /TOC -->

***

## n30p01 回测防撞训练
`CreateTime 2023.06.03`

在n29末，识别二次过滤器测试ok了,本节主要回测下手训防撞,看效果如何;

| 30011 | 手动防撞训练 |
| --- | --- |
| 步骤1 | 强训防撞训练第1步 x 4轮 (多训练多看过各种木棒后,识别准确度更高); |
| 步骤2 | 认知模式手动躲开: `路中偏上,手动上躲成功3次`,`路中偏下,手动下躲成功3次`; |
| 步骤3 | 动物模式试错训练: `路中偏左上`,它应该能迁移过来方案,然后自行进行飞躲; |

```js
//30012-BUG: 碰撞检测误判BUG (明明没撞到,但却判断为撞到了)
//如下,真实情况是鸟是先第二次飞下,然后棒才从279->616的,所以:
//  1. 要么就是鸟飞动画后,没有触发取到真实的棒位置;
//  2. 要么就是鸟飞动画后,压根没触发frame变化,而是在木棒飞完后才触发;
//分析: 根据以下日志触发时间看,应该是第2种,但不一定,可以尝试把触发者打印出来,查下为什么会有这种情况;
//线索: 经调试,发现是鸟飞完动画结束回调未及时执行,而是等到下次主线程不卡时才执行,但不卡可能过了很久(如5s),以往的碰撞检测方法会认为鸟飞了5s,这么慢的飞与木棒撞了,但事实上,鸟压根只飞了0.15s;
//方案: 将动画开始时也回调记录一下动画时长,待完成回调真正执行时,无论它卡了多久,它都能判断鸟在0.15s时就已经飞完了 (只用这0.15s做碰撞检测);
190 [11:14:16:496      BirdGrowPage.m 587] 碰撞检测: 没撞到 棒(0 -> 0) 鸟(362,221 -> 362,221)
191 [11:14:16:497      BirdGrowPage.m 587] 碰撞检测: 没撞到 棒(0 -> 0) 鸟(362,221 -> 362,221)
196 [11:14:17:100      BirdGrowPage.m 587] 碰撞检测: 没撞到 棒(0 -> 48) 鸟(362,221 -> 362,221)
197 [11:14:17:101      BirdGrowPage.m 587] 碰撞检测: 没撞到 棒(48 -> 48) 鸟(362,221 -> 362,221)
435 [11:14:19:608      BirdGrowPage.m 587] 碰撞检测: 没撞到 棒(48 -> 279) 鸟(362,221 -> 362,251)//鸟第1次下飞 (没撞到)
440 [11:14:19:616      BirdGrowPage.m 587] 碰撞检测: 没撞到 棒(279 -> 279) 鸟(362,251 -> 362,251)
441 [11:14:19:617      BirdGrowPage.m 587] 碰撞检测: 没撞到 棒(279 -> 279) 鸟(362,251 -> 362,251)
711 [11:14:23:271      BirdGrowPage.m 587] 碰撞检测: 撞到了 棒(279 -> 616) 鸟(362,251 -> 362,281)//鸟第2次下飞 (明明没撞到,但却判断到撞到了)
//结果: 经修复后,上面BUG修复ok;
```

| 30013 | 二次过滤后末尾也偶尔有准确度低的结果 |
| --- | --- |
| 方案 | 直接把20%并最小4条,改成4条,不要20%了有时20%依然多,留太多也没啥用 `T`; |
| 结果 | 改成4条后,结果发现防撞第1步训练x4后,几乎很准确了 `T`; |

```js
//30014-源自brother迁移过来的canset虽然eff第1名,但实则压根不正确;
=============================== 1 rSolution ===============================
protoFo:F7052[A7050(向7,距124,棒)] 已有方案数:0
测下override过滤生效 (B-F): 原有3 - 过滤1 => 结果2 item场景(B):F4524[A4520(距105,向355,棒)] 取得候选数:2 转成候选模型数:1

0. {1 = S0P1;2 = S1P0;}:(分:1.00) H2N0:(分:1.00) B<F4524 F6996[A4520(距105,向355,棒),飞↑,A6883(距46,向328,棒)]>
1. {}:(分:0.50) H1N0:(分:1.00) I<F6062 F6902[A6059(向8,距115,棒),飞↓,A6899(向14,距97,棒)]>
2. {}:(分:0.50) H1N0:(分:1.00) I<F6143 F6903[A6138(向6,距137,棒),飞↓,A6899(向14,距97,棒)]>
3. {}:(分:0.50) H1N0:(分:1.00) I<F4426 F6906[A4423(向7,距143,棒),飞↓,A6899(向14,距97,棒)]>
4. {}:(分:0.50) H1N0:(分:1.00) I<F4577 F6908[A4571(向10,距105,棒),飞↓,A6899(向14,距97,棒)]>
5. {}:(分:0.50) H1N0:(分:1.00) B<F6062 F6902[A6059(向8,距115,棒),飞↓,A6899(向14,距97,棒)]>
6. {}:(分:0.50) H1N0:(分:1.00) B<F4577 F6908[A4571(向10,距105,棒),飞↓,A6899(向14,距97,棒)]>
7. {}:(分:0.50) H1N0:(分:1.00) B<F6062 F6902[A6059(向8,距115,棒),飞↓,A6899(向14,距97,棒)]>

* 说明: 如下日志,proto为向7,然后在solution决策后,最终优胜者为: 从向355brotherScene迁移来的F6996;
* 复现: `801x4,路中偏上,直投,可顺利躲开`, `然后再重启,路中偏下,直投,可复现如上问题,并错误的向上躲了`
* 思路: 如上日志,源自I的四条,全是正确的canset正确的飞下,只是源自Brother在eff上更优而已;
* 结果. 不用改,再训练多几下自己就好了,其实就是HN需要一个验证过程,在实际测试中,第一次上飞错方向被撞,第二次就改了;
* 共4次试错日志: 第1次偏上,上躲成功; 第2次偏下,上躲失败(错误飞上了); 第3次偏下,下躲成功(正确飞下了); 第4次偏下,下躲成功;
```

| 30015 | 又有一种碰撞误判的情况 |
| --- | --- |
| 说明 | 鸟先躲成功,等棒飞过去半秒后,鸟又飞回来了,被判断为撞到了,日志如下: |
|  | 1. 碰撞检测: 没撞到 棒(0 -> 0) 鸟(380,152 -> 380,152) from:鸟飞开始 |
|  | 2. 碰撞检测: 没撞到 棒(0 -> 91) 鸟(380,152 -> 380,122) from:鸟飞开始 |
|  | 3. 碰撞检测: 没撞到 棒(91 -> 658) 鸟(380,122 -> 380,123) from:鸟飞开始 |
|  | 4. 碰撞检测: 撞到了 棒(658 -> 658) 鸟(380,123 -> 380,123) from:鸟飞结束 |
| 分析 | 看起来这日志撞到时,完全没啥可疑的,鸟在380,123没动,棒在658也没动,是怎么撞到的呢? |
| 线索 | 经调试,发现有时totalTime=0导致woodTime也是0,在分10帧计算时,woodTime做分母,导致radioRect返回的Rect全是NaN |
|  | > 而在求Rect交集时,任何Rect与NaN的交集,全有结果 (非Null),所以导致判断有交集撞到了; |
| 方案 | 针对totalTime为0的情况,支持radioRect返回的一直是初始woodFrame就行,而不是返回NaN无效Rect; |
| 结果 | 改为分母为0时,得数为0,结果回测此bug好了 `T`; |

| 30016 | 继续回归防撞训练 |
| --- | --- |
| 说明 | 经30011步骤训练,`得到FZ80`; |

***

## n30p02 回测觅食训练
`CreateTime 2023.06.09`

在上节中,手训防撞训练FZ80上下躲都ok了,这节开始回归觅食训练;

| 30021 | 手动觅食训练: 训练步骤 |
| --- | --- |
| 1 | 学饿: (`饿,扔随机坚果,不吃,又饿` x 200轮) x 4次; |
| 2 | 学吃: 在认知模式下:`饿,指定方向附近扔坚果,手动飞过去,触发吃掉` x 方向上下各2次; |
| 3 | 试错: `饿,上扔坚果`,它应该能自行飞过去吃掉; |

| 30022 | 觅食训练中遇到识别二次过滤: 性能超慢问题 |
| --- | --- |
| 说明 | 在30021-1训练4次后,第2步训练时,发现识别二次过滤超慢 (超过6s); |
| 优化1 | 在二次过滤中取同级场景节点后,AIPort的防重性能差,优化后从5s提升到1.3s `T`; |
| 优化2 | 概念和时序的识别结果过多,导致本来数据量就大,读硬盘就卡死了,加上限制识别结果数最高20条 `T`; |
| 优化3 | 减少二次识别取得的同层场景数,原来20条能取到80条同层场景太多了,改为强度最强的上限30条吧 `T`; |
| 优化4 | 另外测得在觅食第1步训练4次后,概念识别算法也卡,看下优化下... `经测,有缓存后就不卡了,先不改 T`; |
| 优化5 | 经测在30021-1训练时,二次过滤算法越往后跑好像越卡cpu?比如不卡时执行arrIndex要0.04ms,卡时就2ms `T`; |
|  | 原因: 最后发现,是因为XGDebug的models太多了,导致变慢; |
|  | 方案: 将XGDebug的根据loopId新建的一堆model及时删除 (打印debug结果后,就直接删掉) `T`; |
| 结果 | 本节主要优化了训练过程中的性能问题 (主要集中在二次过滤代码),优化后 `转下表回归训练30021 T`; |

| 30023 | 训练至30021-第3步时,发现EFF总是null,然后也没看到TCEffect统计日志更新 |
| --- | --- |
| 日志 | 0. {}:(分:0.50) (null):(分:0.00) B<F2867 F3796[M1177{↑饿-16},A2864(距25,向290,果),A1191(吃1)]> |
| 说明 | 如上F3796,已经试错三次,但一直没有TCEffect更新HN值,然后打出来日志也一直是null; |
| 调试 | 后调试时,发现在未试错时(仅训练前两步),取得的也是null; |
| 线索 | 后发现,原因是在FoNode.updateConCanset()中,更新effect值的targetIndex全传了1,导致的; |
|  | 注: 取AIEffectStrong时sceneTarget是2,而存时全错传了1,导致下标错误取得effStrong全是nil; |
| 修复 | 将FoNode.updateConCanset()更新effect值的targetIndex改成正确的值 `T`; |

| 30024 | 训练至30021-第2步时,发现P反省太快来不及学吃; |
| --- | --- |
| 日志 | 预测: 感性IRT触发器新增等待反馈:0x7fc4a52a9b90 (F1948[M802{↑饿-16},A1945(距6,向94,果)] useTime:2.37) |
| 触发 | 刚上飞一次,就触发了: F1948[M802{↑饿-16},A1945(距6,向94,果)] spIndex:2 -> (坏) |
| 说明 | 如上日志,第2步训练时从预测到触发更饿,只有2.37s,根本来不急飞吃两下,就触发了(坏的结果); |
| 另外 | 因为每次飞都有飞后视觉,所以其实最终也有好的结果,只是它面向的都是飞一下就吃到的那些; |
|  | >>> 而这些最终好的结果,根本迁移不过来,因为完全场景不一样,一个是两步远左右的距离,一个是一步远左右的距离; |
| 修复 | 1.将饥饿感后,触发更饿的时间调长些 `T`;   2.将扔在附近的坚果更近一些,让它先能顺利学吃 `T`; |

| 30025 | 继续回测觅食训练-测得反思不通过问题 |
| --- | --- |
| 问题 | 训练前两步ok,第3步时,发现15条solution结果,在TCRefrection反思中全失败,日志如下: |
| 日志 | `F4507[M143{↑饿-16},A339(距13,向149,果),飞↑,A4500(向130,距0,果),A2893(吃1)] CUT:1 前匹配度0.66 无效率:1.00` |
|  | `反思评价结果:未通过 (解决任务奖励分21.9 Canset风险:-25.00 懒分:-1.0 = -4.1)` |
| 分析 | 任务pFos被解决奖励分为21到22分,`更饿的`场景风险为-25分,无论如何,风险都大于奖励,所以反思全不通过; |
| 思路 | 日志显示effect无效率为1,所以风险总是-25*1=-25,而无效率=1的原因,是计算effectScore时取得AIEffectStrong为nil导致; |
| 结果 | 所以,继续修复30023的问题,等30023修复了,这里AIEffectStrong不为nil了,本文自然就反思通过了 `转30023 T`; |

```c
30026: 30023修复后,训练至第3步时,明明solution有许多结果,反思也通过了,但却打出了`无计可施`;
0. {}:(分:0.50) H1N0:(分:1.00) I<F790 F4497[M328{↑饿-16},A787(距27,向127,果),飞↑,A4488(距0,向225,果),A2893(吃1)]>
1. {}:(分:0.50) H1N0:(分:1.00) I<F1056 F4494[M436{↑饿-16},A1053(距20,向110,果),飞↑,A4488(距0,向225,果),A2893(吃1)]>
2. {}:(分:0.50) H1N0:(分:1.00) I<F1056 F4514[M436{↑饿-16},A1053(距20,向110,果),飞↑,A4508(距0,向186,果),A2893(吃1)]>
3. {}:(分:0.50) H1N0:(分:1.00) B<F790 F4497[M328{↑饿-16},A787(距27,向127,果),飞↑,A4488(距0,向225,果),A2893(吃1)]>
4. {}:(分:0.50) H1N0:(分:1.00) B<F790 F4497[M328{↑饿-16},A787(距27,向127,果),飞↑,A4488(距0,向225,果),A2893(吃1)]>
5. {}:(分:0.50) H1N0:(分:1.00) B<F342 F4495[M143{↑饿-16},A339(距13,向149,果),飞↑,A4488(距0,向225,果),A2893(吃1)]>
6. {}:(分:0.50) H1N0:(分:1.00) B<F1056 F4494[M436{↑饿-16},A1053(距20,向110,果),飞↑,A4488(距0,向225,果),A2893(吃1)]>
7. {}:(分:0.50) H1N0:(分:1.00) B<F1056 F4514[M436{↑饿-16},A1053(距20,向110,果),飞↑,A4508(距0,向186,果),A2893(吃1)]>
8. {}:(分:0.50) H1N0:(分:1.00) B<F1056 F4494[M436{↑饿-16},A1053(距20,向110,果),飞↑,A4488(距0,向225,果),A2893(吃1)]>
9. {}:(分:0.50) H1N0:(分:1.00) B<F1056 F4514[M436{↑饿-16},A1053(距20,向110,果),飞↑,A4508(距0,向186,果),A2893(吃1)]>

=============================== 2 TCRefrection反思 ============================
F4497[M328{↑饿-16},A787(距27,向127,果),飞↑,A4488(距0,向225,果),A2893(吃1)] CUT:1
反思评价结果:已通过 (解决任务奖励分22.6 Canset风险:-0.00 懒分:-1.0 = 21.6)
>>>>>> rSolution 无计可施

调试: 经调试,发现fo中的mv元素被判断为空概念了 (因为原来mv的port.header全是由nil生成的,而不是由content_ps);
原因: 而在TCRealact中,空概念会从它的具象重新找一个canset替换返回,而mv并不是空概念,它也没具象指向啥canset,所以就全替换成了nil,导致报无计可施 (参考29069-todo8);
修复: 将mv的delta_p和urgent_p当成mv的content_ps去生成header,这样就不会被判断为空概念 `T`;
总结: 本节误判mv为空概念导致觅食训练明明有解却在TCRealact中替换成了nil,导致未行为化的问题;
```

<br><br><br><br><br>
