# 去皮训练: 学去皮

***

<!-- TOC -->

- [去皮训练: 学去皮](#去皮训练-学去皮)
  - [n31p01 去皮训练-学会去皮部分6 (规划搬运训练步骤 & 学会搬运带皮果)](#n31p01-去皮训练-学会去皮部分6-规划搬运训练步骤--学会搬运带皮果)
  - [n31p02 TO类似任务执行太多次问题](#n31p02-to类似任务执行太多次问题)

<!-- /TOC -->

***

## n31p01 去皮训练-学会去皮部分6 (规划搬运训练步骤 & 学会搬运带皮果)
`CreateTime 2023.11.09`

| 31011 | 规划搬运训练,在目前的基础上,训练学会搬运有皮果: 搬运动机部分 |
| --- | --- |
| 简介 | 本表主要解决`搬运`动机问题: 当发现压不到坚果时,搬运后,能压到了 (并将此经验记录成HCanset); |
| 分析 | 1. 木棒确实不可被hCanset实现,但仍可以预测: 即使有木棒,它有些情况下也压不到的; |
|  | 2. 先测下,在压不到的情况下,它是否会预测到这种情况是压不到的 (在30145-步骤4已经训练了各种能否压到的情况); |
| 调试 | 1. 生成任务日志: `pFo:F947[M1{↑饿-16},A944(距72,向182,皮果)]->{-16.00}` |
|  | 2. 找到R解日志: `I<F947 F8544[M1{↑饿-16},A944(距72,向182,皮果),A6552(距121,向17,棒)]> {2 = S0P2;}` |
|  | 思路: 根据以上日志可见,在什么场景下能不能压的到,并不是matchFos预测得到的,而是rCanset的SP稳定性计数出来的; |
| 原则 | **搬运动机源于: 对Canset追求更高的SP稳定性;** |
| 测下 | 在FZ885的基础上再跑跑`30145-步骤4`,看下日志,能不能激活rCanset,然后增强SP? `具体测的跟进,转以下几张表` |

**小结: 31011分析了搬运动机,但被下方几张表的BUG卡住,所以搬运动机要转至31016再继续;**

```c
31012-木棒cansetA的deltaTime=0的问题;
//说明: 如下日志,rCanset能激活,也能顺利转到H任务A3568(棒),但问题在于,取到出现木棒的时间是0s,导致触发器很快,根本来不及等到feedbackTOR反馈;
_Fo行为化第 3/10 个: F4591[M1{↑饿-16},A159(向335,距60,皮果),A3568(向331,距56,棒),A3572(向274,距27,棒)...
---//构建行为化帧触发器:0x600000643b10 for:饿 time:0.00
_Fo行为化第 3/10 个: F4026[M1{↑饿-16},A384(向23,距67,皮果),A3568(向331,距56,棒),A3572(向274,距27,棒)...
---//构建行为化帧触发器:0x600000655c70 for:饿 time:0.00
_Fo行为化第 3/10 个: F4026[M1{↑饿-16},A384(向23,距67,皮果),A3568(向331,距56,棒),A3572(向274,距27,棒)...
---//构建行为化帧触发器:0x6000006b79d0 for:饿 time:0.00
//分析: 经查,在生成尤其决策期的一些fo时,比如cansetFo或者feedbackRegroupFo时,order的时间不是时间戳,而是本身就是deltaTime值;
//解答: 这导致在生成fo时,再次计算deltaTime,会算错,算成0,把输入时是输入时间戳还是已经是deltaTime加以区分,改后好了 `T`;
```

| 31013 | 改掉deltaTime=0的BUG后,重新训练步骤3到步骤5 |
| --- | --- |
| 简介 | 上表BUG修复后,因为这个BUG主要影响cansetFo生成和决策期,所以相关的就是步骤2到5,本表重新训练下这三步 |
| 注1 | 为了单纯训练去皮相关(避免疼痛影响它安静思考),本表将`随机出生`改为`随机路边出生`; |
| 步骤1 | **带皮学饿: 认知模式(`饿(持续饿感3次),扔随机带皮坚果,不吃,又饿`x200轮);** =>存为FZ871 |
| 步骤2 | **学认木棒: 认知模式(`随机路边出生,扔木棒` x 300轮);** =>存为FZ882 |
| 步骤3 | **带皮学吃: 认知模式(`饿,路边出生,路上就近扔带皮果,扔棒去皮,手动飞过去,触发吃掉`)x近中远上下各1次** =>存为FZ893 |
|  | > 重点日志: 看下`newRCanset`日志,应该能生成许多(避免更饿)RCanset; |
| 步骤4 | **学H去皮: 动物模式(`随机路边出生,饿,扔随机带皮果,扔木棒`x200轮);** =>存为FZ894 |
|  | > 重点日志: 看下`newHCanset`日志,应该能生成许多(去皮)HCanset; |
| 步骤5 | **预想与实际类比: 动物模式(`步骤3一致`)x近中远上下各1次** (参考30154-测1) =>存为FZ895 |
|  | > 重点日志: 看下`预想与实际`日志,应该能类比生成许多抽象RCanset; |
| 结果 | 本表在FZ882的基础上重新训练下步骤3到5,并存为FZ893,FZ894,FZ895; |

**小结: 以上31012-31013修复了deltaTime=0的BUG,并重新训练了FZ893,894,895;**

```c
31014-在31013-步骤5训练时,发现"预想与实际类比"的结果不好,调试日志如下:
1. 新proto: F9190[M1{↑饿-16},A515(距32,向72,皮果),A9163(距82,向18,棒),A9168(距26,向90,棒),A9169(向98,距9,果),飞↑,A9177(距53,向160,棒),A9178(距0,向122,果),A9183(向163,距54,棒),A3547(吃1)]
2. 与ass: F8938[M1{↑饿-16},A515(距32,向72,皮果),A8912(距79,向17,棒),A8917(距23,向88,棒),A8918(向94,距10,果),飞↑]
3. 外类比构建时序: F9029[A13(饿16,7),A515(距32,向72,皮果),飞↑]->{} from: (protoFo(1):assFo(2))
RCanset预想与实际类比:F9029[A13(饿16,7),A515(距32,向72,皮果),飞↑] (curS:F8938 状态:Runing fromPFo:F518 帧:2)
//问题: 如上日志中,proto和ass还是挺相似的,但类比出的结果却没有`棒`,另外ass的末帧也没有收集到`吃`;
//复现: 用现在的`FZ895,近下出生,跑步骤3`,然后即可复现触发"预想与实际类比";
//分析: 应该是木棒确实mIsC没匹配上,毕竟现在的新木棒在似层能匹配上的机率很低(因为概念识别结果的条数少,而似层总数特别多);
//方案: 可以尝试下多跑跑步骤5,让Canset更多的触发类比,然后过度到交层,只要过度到交层了,此问题也就自然解决了;
//TODO1: 在同位置出生然后同样相对位置扔有皮果，然后跑步骤5，看能不能“预想与实际类比”出交层结果？训练日志如下：
第1行. RCanset预想与实际类比:F9029[A13(饿16,7),A515(距32,向72,皮果),飞↑] (curS:F8938 状态:Runing fromPFo:F518 帧:2)
第2行.RCanset预想与实际类比:F9267[A13(饿16,7),A515(距32,向72,皮果),A9266(距23,棒),飞↑] (curS:F8938 状态:Runing fromPFo:F518 帧:2)
第3行.RCanset预想与实际类比:F9303[A13(饿16,7),A515(距32,向72,皮果),A9302(向88,棒),飞↑] (curS:F8938 状态:Runing fromPFo:F518 帧:2)
第4行.RCanset预想与实际类比:F9303[A13(饿16,7),A515(距32,向72,皮果),A9302(向88,棒),飞↑] (curS:F8938 状态:ActNo fromPFo:F518 帧:2)
第5行.RCanset预想与实际类比:F9350[A13(饿16,7),A2528(距67,向141,皮果),A9349(距26,棒),A9348(距9,果),飞↑,A9347(距0,果),A3547(吃1)] (curS:F9192 状态:ActYes fromPFo:F2531 帧:2)
//结果: 从todo1训练日志可见，本表方案可以得到交层“无距棒、无向棒、无向果” `可将本表方案整理成训练步骤6,转31015`;
```

| 31015 | 预想与实际类比得到交层Canset -> 训练步骤6 |
| --- | --- |
| 步骤6 | **过渡到交层Canset: 动物模式(路边出生,饿,就近Y大致对齐路中扔皮果,扔棒,手动飞至,触发吃掉)x上下各5次** =>存为FZ896 |
|  | > 之所以要Y大致对齐,是为了让鸟和果的相对位置相对稳定,这样能帮助从似层快速过渡到交层; |
|  | > 重点日志: 看下`预想与实际`日志,应该能类比生成许多`交层Canset` (参考31014-方案&第5行日志); |

**小结: 31014-31015测得了抽象Canset因过度抽象缺失帧的问题,所以追加了训练步骤6,以训练交层Canset(交层能避免缺失帧问题);**

| 31016 | 搬运动机 -> 训练步骤7 |
| --- | --- |
| 简介 | 在31011分析了搬运动机的实现思路(其实就是给RCanset训练SP值),本表追加实际的训练步骤6,来试下; |
| 步骤7 | **搬运动机: 在FZ896基础上再跑跑步骤4** `参考31011-原则&测下` =>存为FZ897; |
|  | > 重点日志: 看下`OR反省`日志,rCanset的SP有增强; |
| 结果 | 比较稳定SP的Canset激活后,会显示[饿,路中带皮果,棒,无皮果,飞,吃],但可能带皮果不在路上呢?就需要搬运了 `转下表`; |

| 31017 | 搬运训练 -> 训练步骤8 |
| --- | --- |
| 简介 | 在31016-结果中指出了如果带皮果不在路上的情况,本表则针对此H需求做`学会搬运HCanset`; |
| 副目标 | 为快速达成训练目标,可以**尽量使用迁移和试错来学会搬运** (即只训练一两次hCanset,剩下的全用迁移和试错来完成); |
| 思路 | 1. 分析下RCanset需要什么距向的有皮果,然后生成为H任务后,把不符合的有皮果,搬运成符合的有皮果,并生成为hCanset; |
|  | 2. 这样下回再激活HDemand有皮果时,就可以找到hCanset经验,并尝试通过搬运来加工符合条件(搬到路上)的有皮果; |
| 前验 | **通过以下几步尝试,先提前验证一下上面的思路能不能跑的通;** |
|  | 说明: 主要验证**触发带皮果H任务,不符时,符合时,然后再试下能不能学会HCanset**,这4条都提前验证下; |
| 前验1 | 触发HDemand: 试下仅点击饿,能不能预测到更饿,然后得到rCanset,并将有皮果转成hDemand; |
|  | 问题1. 点击饥饿时,没有立马预测到更饿; |
|  | 解答1. 经查pInput时连概念识别都没调用,所以识别不到饿了会更饿,改先支持下,然后再测 `T`; |
|  | 问题2. 在饥饿调用概念识别时,全含检查全不通过; |
|  | 解答2. 因为mvAlg的count取contentPorts返回0,导致全含失败,改为用content_ps.count后返回2,全含能通过了 `T`; |
|  | 问题3. mv概念识别ok后,时序识别结果仍是0条; |
|  | 求解3. 经查,没有[饿]->{更饿}时序,导致识别不到,经查前7步从来没训练过[饿]->{更饿}; |
|  | 解答3. 可以在步骤2和步骤3之间先插入一步`饿了更饿`的训练 `转31018-步骤2.5`; |
|  | 问题4. 在31018-FZ907的基础上,点击饿发现: `饿了更饿`生成的任务无计可施,没有激活rCanset; |
|  | 求解4. 经查,饿了更饿没rCanset的原因是,手动训练时,点击重启太早,导致realMaskFo还未收集完成就重启了; |
|  | 解答4. 改为在看到思维闲时(TC的FPS为0持续三秒)再重启即可 `T`; |
| 前验2 | 符合时: 试下有皮果扔路上时H任务能反馈到; |
| 前验3 | 不符时: 然后再试下不扔到路上时,H任务反馈不到; |
| 前验4 | 学会HCanset: 然后再试下不扔到路上,但搬运到路上,然后又反馈到; |
| 步骤8 | **搬运训练: 动物模式(路下出生,路下扔带皮果,路上带皮果转为h任务后,把坚果搬运到路上,扔木棒,飞,吃)** |

**小结: 以上规划了"搬运动机"和"搬运训练",但搬运训练之前的前验并不顺利,因此需要加步骤2.5等,见下表;**

| 31018 | 插入一步: 步骤2.5 |
| --- | --- |
| 步骤2.5 | 饿了更饿: 认知模式(`饿(持续饿感3次)`x20轮); =>存为FZ902.5 |
| 实践 | 加了步骤2.5后,对后面步骤的训练都有影响,所以需要重整理下所有步骤并重新训练下: **↓↓↓** |
| 回测 | 按如下8个步骤回测下 (只需要训练2.5之后的步骤,之前的不变可复用FZ871和FZ882); |
| 步骤1 | 带皮学饿: 认知模式(`饿(持续饿感3次),扔随机带皮坚果,不吃,又饿`x200轮); =>存为FZ871 |
| 步骤2 | 学认木棒: 认知模式(`随机路边出生,扔木棒` x 300轮); =>存为FZ882 |
| 步骤2.5 | 饿了更饿: 认知模式(`饿(持续饿感3次)`x20轮); =>存为FZ902.5 |
|  | > 重点日志: 看下点了饿后,立马能识别到`[饿]->{更饿}`; |
| 步骤3 | 带皮学吃: 认知模式(`饿,路边出生,路上就近扔带皮果,扔棒去皮,手动飞过去,触发吃掉`)x近中远上下各1次 =>存为FZ903 |
|  | > 重点日志: 看下`newRCanset`日志,应该能生成许多(避免更饿)RCanset; |
| 步骤4 | 学H去皮: 动物模式(`随机路边出生,饿,扔随机带皮果,扔木棒`x70轮); =>存为FZ904 |
|  | > 重点日志: 看下`newHCanset`日志,应该能生成许多(去皮)HCanset; |
|  | 问题1. 在加入步骤2.5后,步骤4学不到去皮的HCanset了,需要再跑跑分析下原因; |
|  | 分析1. 看起来是步骤3得到的newRCanset太具象了,很难走到`无皮果HDemand`那一帧; |
|  | 解答1. 可以先跑跑后面的`预想与实际类比`和`过渡到交层`,然后再来跑第4步看下能不能得到newHCanset; |
|  | 实践1. 把步骤4(学H去皮)调整到步骤6(过渡到交层Canset)之后 `转3101a`; |
| 步骤5-8 | 本表只训练到步骤4....步骤5到步骤8因以上`步骤4-问题1`导致本表未继续训练,略; |
| 结果1 | 本表补了个步骤2.5,然后整个后面的都要重新训练,有点太麻烦 `太麻烦的问题 转31019`; |
| 结果2 | 本表测得步骤4(学H去皮)训练未得到`去皮newHCanset`的问题 `转3101a`; |

| 31019 | 最近总是发现训练步骤会缺一些东西,导致推进不顺 |
| --- | --- |
| 分析 | 比如上面的步骤2.5就是缺了饿了更饿,而31017-问题4又测得了饿了更饿没rCanset; |
| 重点 | 如果每次缺了什么,就补一个步骤,再重新训练,补一点点就重新跑一次训练,那得累死; |
| 方案 | 先废除训练步骤,边跑边测边推进,缺什么就训练什么,灵活点搞; |
|  | 优点: 这么做的优点是,灵活训练,缺什么训练什么,更容易发现问题,推进测试和修补系统细节问题; |
| 结果 | 先采用本表方案,**等灵活跑顺了,再改回:规划训练步骤;** `T` |
| 追加 | `灵活跑`的方案,还是灵活用吧,想用时用用,但主要还是以规划步骤为主线 `T`; |

**小结: 31018训练了: 饿了更饿,但发现"学H去皮"不顺利,转下表把学H去皮后置一些;**

| 3101a | 将步骤4后调到步骤6之后 |
| --- | --- |
| 说明 | 本表在31018的基础上,将31018-步骤4,调整到步骤6之后 (因为在RCanset更抽象后,); |
| 解析 | 本表: 步骤1-3是基础训练,4-6是rCanset训练,7-8是搬运带皮果训练,9之后是去皮训练; |
| 步骤1 | 带皮学饿: 认知模式(`饿(持续饿感3次),扔随机带皮坚果,不吃,又饿`x200轮); =>存为FZ871 |
| 步骤2 | 学认木棒: 认知模式(`随机路边出生,扔木棒` x 300轮); =>存为FZ882 |
| 步骤3 | 饿了更饿: 认知模式(`饿(持续饿感3次)`x20轮); =>存为FZ913 |
|  | > 重点日志: 看下点了饿后,立马能识别到`[饿]->{更饿}`; |
| 步骤4 | 带皮学吃: 认知模式(`饿,路边出生,路上就近扔带皮果,扔棒去皮,手动飞过去,触发吃掉`)x近中远上下各1次 =>存为FZ914 |
|  | > 重点日志: 看下`newRCanset`日志,应该能生成许多(避免更饿)RCanset; |
| 步骤5 | 预想与实际类比: 动物模式(`与带皮学吃一致`)x近中远上下各1次 (参考30154-测1) =>存为FZ915 |
|  | > 重点日志: 看下`预想与实际`日志,应该能类比生成许多抽象RCanset; |
| 步骤6 | 过渡到交层Canset: 动物模式(路边出生,饿,就近Y大致对齐路中扔皮果,扔棒,手动飞至,触发吃掉)x上下各3次 =>存为FZ916 |
|  | > 说明: 之所以要Y大致对齐,是为了让鸟和果的相对位置相对稳定,这样能帮助从似层快速过渡到交层; |
|  | > 重点日志: 看下`预想与实际`日志,应该能类比生成许多`交层Canset` (参考31014-方案&第5行日志); |
| 步骤7 | 搬运动机: 动物模式(`随机路边出生,饿,扔随机带皮果,扔木棒`x70轮) =>存为FZ917; |
|  | > 重点日志: 看下`OR反省`日志,rCanset的SP有增强 **(SP的增强就等价于搬运动机)**; |
|  | > 说明1: 搬运动机其实就是激活了`路中带皮果`,然后转成HDemand,来加工带皮果从路边到路中 `参考31011-原则&测下`; |
|  | > 说明2: 激活SP最稳定的Canset `如:[饿,路中带皮果,棒,无皮果,飞,吃]`,而第2帧带皮果不在路上就转为H任务搬运 `转下步`; |
| 步骤8 | 搬运训练: 动物模式(路下出生,路下扔带皮果,路上带皮果转为h任务后,把坚果搬运到路上,扔木棒,飞,吃) |
| 步骤9 | 学H去皮: 动物模式(`随机路边出生,饿,扔随机带皮果,扔木棒`x70轮) =>存为FZ919 |
|  | > 重点日志: 看下`newHCanset`日志,应该能生成许多(去皮)HCanset; |
|  | > 说明: 其实学H去皮不需要特意训练,只要有了"路中带皮果",无非就是看到木棒后,自然就有了"无皮果"; |

**小结: 本表在上面几张表:新增了"饿了更饿"和"学H去皮"后置后,重新整理了一下9个步骤;**

| 3101b | 上表步骤7训练后,发现OR反省中SP值普遍<3 |
| --- | --- |
| 简介 | 因为SP的增强就等价于搬运动机,所以能解决饥饿问题的正确rCanset能够增强SP稳定性非常重要; |
| 分析 | 1. 只有步骤4到6顺利吃到了,但次数很少,而步骤7中的70次经历都是没吃到的; |
|  | 2. 即步骤4到6的rCanset一次次激活又失败,它们的SP稳定性都已经很低; |
|  | 3. 此时TCTransfer迁移到新场景上的rCanset会不会继承那个很低的SP呢? |
|  | 4. 如果不会继承SP值,就可能导致本表的问题,即迁移过来的SP默认为S0P0,但稳定性却大于那些很低的rCanset; |
| 线索 | 5. 从而导致总是比较新迁移出来的rCanset被最终激活,它的SP值也必然是<3的(因为没继承迁移前的SP值); |
| 方案 | 在TCTransfer迁移出新canset时,可以继承(/推举)一下SP值; |
| todo1 | 继承算法加上随便继承SP值 `T`; |
| todo2 | 推举算法也加上SP推举初始值 (参考下方方案2及相关分析) `T`; |
|  | 方案1. 暂不加推举SP值 `5%` |
|  | >>> 推举时也推举SP值吧 (比如吃了苹果和梨了,会认为水果大几率能吃); |
|  | 方案2. 谁推举就加谁的SP初始值 `95%` |
|  | >>> 防重复推举: 推举的canset可能本来就有,已推举过的不重复推举; |
|  | >>> 推举SP机制: 推举一次更新一次SP,即谁新推举时,计入它的SP即可,这样其实与方案3是等效的; |
|  | 方案3. 从多个具象里综合sumSP值 `5%` |
|  | >>> 方案3求综合sumSP值有点废性能不可取; |
|  | 结果: 根据以上分析,选择方案2进行实践 `T`; |
| todo3 | 推举或继承都要防重 (参考todo2-方案2-防重复) `本就支持 T`; |
| todo4 | 推举和继承SP值的机制都是异步做,谁推举/继承,谁的SP值就计进去 (参考todo2-方案2-推举SP机制) `T`; |
| todo5 | 构建cansetFo时,改为场景内防重,而不是全局防重 (为什么这么做的原因如下) `T`; |
|  | 为什么这么做: 如果全局防重,在各场景生成一模一样的cansetFo时,分别继承SP,会混在一起,SP全累计到一起; |
|  | 比如1: 在家吃饭的SPEFF感觉,和在野外独自一人吃饭肯定不一样,虽然都是吃饭,但场景不同,不应该混在一起; |
|  | 比如2: 在北京吃龙虾不行,在家是可以的 (这些canset虽然内容一样,但SPEFF完全不同,不能窜); |
| todo6 | 同理todo5:在预想与实际类比构建absCanset时 和 自然未发生时创建canset,也都改为场景内防重 `T`; |
| 结果 | 改完后,再跑FZ917,看OR反省日志,有了SP值>6的情况了,虽然不是很多; |

**小结: 本表写了: 1.迁移时连带SP值 2.构建Canset改为场景内防重**

**总结: 本节跑搬运动机,并修复了一些细节问题,不过搬运动机依然还不是很顺,`FZ917,饿,路边有皮果,棒`,这个过程中生成的hDemand往往是针对木棒(这种情况占90%以上),而不是针对带皮果(占比2%左右),但日志太杂而乱了,日志几乎是不可读状态,TO执行的循环太多次类似的在跑,转下节先把这个TO循环太杂乱的问题搞搞再说;**

***

## n31p02 TO类似任务执行太多次问题
`CreateTime 2023.12.11`

见上节末总结,TO循环太杂乱了,全是类似的Demand在反反复复的跑;

| 31021 | TO循环虽然与TI分离了,但针对类似任务还是执行太多次了 |
| --- | --- |
| 说明 | 比如感到饿,然后看到带皮果,然后看到木棒,这个过程中,触发多次识别,然后触发Demand,触发TO |
| 分析 | 能不能把这种非常类似的任务都整合一下,避免反反复复的TO过程,又耗能,又没啥用,还看起来混乱; |
| 方案 | 看下类似的Demand在有新帧输入时,全更新到原类似RootDemand中,而不是生成为新的RootDemand; |
| 问题 | 分析root防重的判定方法: 即怎么判定各个pFo是属于"类似"的,如以下两个时序: |
|  | 比如: 先识别到:`F1[A1,B1,C1],cutIndex=B1`; 过了一会又识别到:`F2[A2,B2,C2],cutIndex=C2`; |
|  | 疑问: F1和F2是"类似"时序吗?如果A1和A2虽然有共同抽象,或者有mIsC关系,或者二者甚至就是同一个节点,那么算"类似帧"吗? |
| 解答 | **可以以A1和A2都在同一个概念识别的matchAlgs结果中,来判断它们是"类似的"**; |
| todo1 | 在DemandManager生成Root时,判断pFo,将所有"类似"的pFo都归到同一个rootDemand下; |

| 3101x | 正式开始做: 步骤8-搬运训练 |
| --- | --- |
| 第1步 | 试下能必现搬运动机 |
| 第2步 | 再做下搬运看能够学到搬运hCanset |

<br><br><br><br><br>
